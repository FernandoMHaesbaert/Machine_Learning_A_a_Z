<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.26">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Dr.&nbsp;Fernando Machado Haesbaert">

<title>Machine Learning de A a Z</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="Machine_Learning_A_a_Z_files/libs/clipboard/clipboard.min.js"></script>
<script src="Machine_Learning_A_a_Z_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="Machine_Learning_A_a_Z_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="Machine_Learning_A_a_Z_files/libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="Machine_Learning_A_a_Z_files/libs/quarto-html/popper.min.js"></script>
<script src="Machine_Learning_A_a_Z_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Machine_Learning_A_a_Z_files/libs/quarto-html/anchor.min.js"></script>
<link href="Machine_Learning_A_a_Z_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Machine_Learning_A_a_Z_files/libs/quarto-html/quarto-syntax-highlighting-597958c53c93a607afca12fd375c57ed.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Machine_Learning_A_a_Z_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Machine_Learning_A_a_Z_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Machine_Learning_A_a_Z_files/libs/bootstrap/bootstrap-8db4201b14708b18b0c4eb564971129b.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<style>html{ scroll-behavior: smooth; }</style>
<script src="Machine_Learning_A_a_Z_files/libs/kePrint-0.0.1/kePrint.js"></script>

<link href="Machine_Learning_A_a_Z_files/libs/lightable-0.0.1/lightable.css" rel="stylesheet">

<link href="Machine_Learning_A_a_Z_files/libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet">

<script src="Machine_Learning_A_a_Z_files/libs/pagedtable-1.1/js/pagedtable.js"></script>


  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article toc-left">
<div id="quarto-sidebar-toc-left" class="sidebar toc-left">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#a" id="toc-a" class="nav-link active" data-scroll-target="#a"><span class="header-section-number">1</span> A</a>
  <ul class="collapse">
  <li><a href="#accuracy-acur√°cia" id="toc-accuracy-acur√°cia" class="nav-link" data-scroll-target="#accuracy-acur√°cia"><span class="header-section-number">1.1</span> Accuracy (Acur√°cia)</a>
  <ul class="collapse">
  <li><a href="#exemplo-c√°lculo-da-acur√°cia-em-r" id="toc-exemplo-c√°lculo-da-acur√°cia-em-r" class="nav-link" data-scroll-target="#exemplo-c√°lculo-da-acur√°cia-em-r"><span class="header-section-number">1.1.1</span> Exemplo: C√°lculo da Acur√°cia em R</a></li>
  </ul></li>
  <li><a href="#adaboost-adaptive-boosting" id="toc-adaboost-adaptive-boosting" class="nav-link" data-scroll-target="#adaboost-adaptive-boosting"><span class="header-section-number">1.2</span> AdaBoost (Adaptive Boosting)</a>
  <ul class="collapse">
  <li><a href="#exemplo-algoritmo-adaboost-para-classificar-flores-do-conjunto-de-dados-iris." id="toc-exemplo-algoritmo-adaboost-para-classificar-flores-do-conjunto-de-dados-iris." class="nav-link" data-scroll-target="#exemplo-algoritmo-adaboost-para-classificar-flores-do-conjunto-de-dados-iris."><span class="header-section-number">1.2.1</span> Exemplo: algoritmo AdaBoost, para classificar flores do conjunto de dados Iris.</a></li>
  </ul></li>
  <li><a href="#aglomerativo-hierarchical-clustering" id="toc-aglomerativo-hierarchical-clustering" class="nav-link" data-scroll-target="#aglomerativo-hierarchical-clustering"><span class="header-section-number">1.3</span> Aglomerativo Hierarchical Clustering</a>
  <ul class="collapse">
  <li><a href="#exemplo-em-r-clustering-aglomerativo-com-hclust" id="toc-exemplo-em-r-clustering-aglomerativo-com-hclust" class="nav-link" data-scroll-target="#exemplo-em-r-clustering-aglomerativo-com-hclust"><span class="header-section-number">1.3.1</span> Exemplo em R ‚Äì clustering aglomerativo com hclust:</a></li>
  </ul></li>
  <li><a href="#aic-akaike-information-criterion-crit√©rio-de-akaike" id="toc-aic-akaike-information-criterion-crit√©rio-de-akaike" class="nav-link" data-scroll-target="#aic-akaike-information-criterion-crit√©rio-de-akaike"><span class="header-section-number">1.4</span> AIC ‚Äì Akaike Information Criterion (Crit√©rio de Akaike)</a>
  <ul class="collapse">
  <li><a href="#exemplo-compara√ß√£o-de-modelos-lineares-com-aic" id="toc-exemplo-compara√ß√£o-de-modelos-lineares-com-aic" class="nav-link" data-scroll-target="#exemplo-compara√ß√£o-de-modelos-lineares-com-aic"><span class="header-section-number">1.4.1</span> Exemplo: compara√ß√£o de modelos lineares com AIC:</a></li>
  </ul></li>
  <li><a href="#artificial-neural-networks-anns" id="toc-artificial-neural-networks-anns" class="nav-link" data-scroll-target="#artificial-neural-networks-anns"><span class="header-section-number">1.5</span> Artificial Neural Networks (ANNs)</a>
  <ul class="collapse">
  <li><a href="#exemplo-em-r-rede-feed-forward-para-regress√£o-com-pacote-nnet" id="toc-exemplo-em-r-rede-feed-forward-para-regress√£o-com-pacote-nnet" class="nav-link" data-scroll-target="#exemplo-em-r-rede-feed-forward-para-regress√£o-com-pacote-nnet"><span class="header-section-number">1.5.1</span> Exemplo em R: Rede feed-forward para regress√£o com pacote <code>{nnet}</code></a></li>
  </ul></li>
  </ul></li>
  <li><a href="#b" id="toc-b" class="nav-link" data-scroll-target="#b"><span class="header-section-number">2</span> B</a>
  <ul class="collapse">
  <li><a href="#bagging-bootstrap-aggregating" id="toc-bagging-bootstrap-aggregating" class="nav-link" data-scroll-target="#bagging-bootstrap-aggregating"><span class="header-section-number">2.1</span> Bagging (Bootstrap Aggregating)</a></li>
  </ul></li>
  <li><a href="#c" id="toc-c" class="nav-link" data-scroll-target="#c"><span class="header-section-number">3</span> C</a>
  <ul class="collapse">
  <li><a href="#cross-validation-cv" id="toc-cross-validation-cv" class="nav-link" data-scroll-target="#cross-validation-cv"><span class="header-section-number">3.1</span> Cross-Validation (CV)</a></li>
  </ul></li>
  <li><a href="#d" id="toc-d" class="nav-link" data-scroll-target="#d"><span class="header-section-number">4</span> D</a>
  <ul class="collapse">
  <li><a href="#decision-trees-√°rvores-de-decis√£o" id="toc-decision-trees-√°rvores-de-decis√£o" class="nav-link" data-scroll-target="#decision-trees-√°rvores-de-decis√£o"><span class="header-section-number">4.1</span> Decision Trees (√Årvores de Decis√£o)</a></li>
  <li><a href="#divisive_hierarchical_clustering" id="toc-divisive_hierarchical_clustering" class="nav-link" data-scroll-target="#divisive_hierarchical_clustering"><span class="header-section-number">4.2</span> Divisive Hierarchical Clustering</a>
  <ul class="collapse">
  <li><a href="#exemplo-em-r-clustering-divisivo-com-diana" id="toc-exemplo-em-r-clustering-divisivo-com-diana" class="nav-link" data-scroll-target="#exemplo-em-r-clustering-divisivo-com-diana"><span class="header-section-number">4.2.1</span> Exemplo em R ‚Äì clustering divisivo com diana</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#e" id="toc-e" class="nav-link" data-scroll-target="#e"><span class="header-section-number">5</span> E</a>
  <ul class="collapse">
  <li><a href="#ensemble-learning" id="toc-ensemble-learning" class="nav-link" data-scroll-target="#ensemble-learning"><span class="header-section-number">5.1</span> Ensemble Learning</a></li>
  </ul></li>
  <li><a href="#f" id="toc-f" class="nav-link" data-scroll-target="#f"><span class="header-section-number">6</span> F</a>
  <ul class="collapse">
  <li><a href="#feature-scaling" id="toc-feature-scaling" class="nav-link" data-scroll-target="#feature-scaling"><span class="header-section-number">6.1</span> Feature Scaling</a></li>
  </ul></li>
  <li><a href="#g" id="toc-g" class="nav-link" data-scroll-target="#g"><span class="header-section-number">7</span> G</a>
  <ul class="collapse">
  <li><a href="#gradient-descent-gd" id="toc-gradient-descent-gd" class="nav-link" data-scroll-target="#gradient-descent-gd"><span class="header-section-number">7.1</span> Gradient Descent (GD)</a></li>
  </ul></li>
  <li><a href="#h" id="toc-h" class="nav-link" data-scroll-target="#h"><span class="header-section-number">8</span> H</a>
  <ul class="collapse">
  <li><a href="#hyperparameter-tuning" id="toc-hyperparameter-tuning" class="nav-link" data-scroll-target="#hyperparameter-tuning"><span class="header-section-number">8.1</span> Hyperparameter Tuning</a></li>
  </ul></li>
  <li><a href="#i" id="toc-i" class="nav-link" data-scroll-target="#i"><span class="header-section-number">9</span> I</a>
  <ul class="collapse">
  <li><a href="#instance-based-learning" id="toc-instance-based-learning" class="nav-link" data-scroll-target="#instance-based-learning"><span class="header-section-number">9.1</span> Instance-Based Learning</a></li>
  </ul></li>
  <li><a href="#j" id="toc-j" class="nav-link" data-scroll-target="#j"><span class="header-section-number">10</span> J</a>
  <ul class="collapse">
  <li><a href="#jaccard-index" id="toc-jaccard-index" class="nav-link" data-scroll-target="#jaccard-index"><span class="header-section-number">10.1</span> Jaccard Index</a></li>
  </ul></li>
  <li><a href="#k" id="toc-k" class="nav-link" data-scroll-target="#k"><span class="header-section-number">11</span> K</a>
  <ul class="collapse">
  <li><a href="#k-nearest-neighbors-knn" id="toc-k-nearest-neighbors-knn" class="nav-link" data-scroll-target="#k-nearest-neighbors-knn"><span class="header-section-number">11.1</span> K-Nearest Neighbors (KNN)</a></li>
  </ul></li>
  <li><a href="#l" id="toc-l" class="nav-link" data-scroll-target="#l"><span class="header-section-number">12</span> L</a>
  <ul class="collapse">
  <li><a href="#logistic-regression" id="toc-logistic-regression" class="nav-link" data-scroll-target="#logistic-regression"><span class="header-section-number">12.1</span> Logistic Regression</a></li>
  </ul></li>
  <li><a href="#m" id="toc-m" class="nav-link" data-scroll-target="#m"><span class="header-section-number">13</span> M</a>
  <ul class="collapse">
  <li><a href="#model-overfitting" id="toc-model-overfitting" class="nav-link" data-scroll-target="#model-overfitting"><span class="header-section-number">13.1</span> Model Overfitting</a></li>
  </ul></li>
  <li><a href="#n" id="toc-n" class="nav-link" data-scroll-target="#n"><span class="header-section-number">14</span> N</a>
  <ul class="collapse">
  <li><a href="#normalization" id="toc-normalization" class="nav-link" data-scroll-target="#normalization"><span class="header-section-number">14.1</span> Normalization</a></li>
  </ul></li>
  <li><a href="#o" id="toc-o" class="nav-link" data-scroll-target="#o"><span class="header-section-number">15</span> O</a>
  <ul class="collapse">
  <li><a href="#outliers" id="toc-outliers" class="nav-link" data-scroll-target="#outliers"><span class="header-section-number">15.1</span> Outliers</a></li>
  </ul></li>
  <li><a href="#p" id="toc-p" class="nav-link" data-scroll-target="#p"><span class="header-section-number">16</span> P</a>
  <ul class="collapse">
  <li><a href="#principal-component-analysis-pca" id="toc-principal-component-analysis-pca" class="nav-link" data-scroll-target="#principal-component-analysis-pca"><span class="header-section-number">16.1</span> Principal Component Analysis (PCA)</a></li>
  </ul></li>
  <li><a href="#q" id="toc-q" class="nav-link" data-scroll-target="#q"><span class="header-section-number">17</span> Q</a>
  <ul class="collapse">
  <li><a href="#q-learning" id="toc-q-learning" class="nav-link" data-scroll-target="#q-learning"><span class="header-section-number">17.1</span> Q-Learning</a></li>
  </ul></li>
  <li><a href="#r" id="toc-r" class="nav-link" data-scroll-target="#r"><span class="header-section-number">18</span> R</a>
  <ul class="collapse">
  <li><a href="#regularization" id="toc-regularization" class="nav-link" data-scroll-target="#regularization"><span class="header-section-number">18.1</span> Regularization</a></li>
  </ul></li>
  <li><a href="#s" id="toc-s" class="nav-link" data-scroll-target="#s"><span class="header-section-number">19</span> S</a>
  <ul class="collapse">
  <li><a href="#support-vector-machines-svm" id="toc-support-vector-machines-svm" class="nav-link" data-scroll-target="#support-vector-machines-svm"><span class="header-section-number">19.1</span> Support Vector Machines (SVM)</a></li>
  </ul></li>
  <li><a href="#t" id="toc-t" class="nav-link" data-scroll-target="#t"><span class="header-section-number">20</span> T</a>
  <ul class="collapse">
  <li><a href="#training-set" id="toc-training-set" class="nav-link" data-scroll-target="#training-set"><span class="header-section-number">20.1</span> Training Set</a></li>
  </ul></li>
  <li><a href="#u" id="toc-u" class="nav-link" data-scroll-target="#u"><span class="header-section-number">21</span> U</a>
  <ul class="collapse">
  <li><a href="#underfitting" id="toc-underfitting" class="nav-link" data-scroll-target="#underfitting"><span class="header-section-number">21.1</span> Underfitting</a></li>
  </ul></li>
  <li><a href="#v" id="toc-v" class="nav-link" data-scroll-target="#v"><span class="header-section-number">22</span> V</a>
  <ul class="collapse">
  <li><a href="#validation-set" id="toc-validation-set" class="nav-link" data-scroll-target="#validation-set"><span class="header-section-number">22.1</span> Validation Set</a></li>
  </ul></li>
  <li><a href="#w" id="toc-w" class="nav-link" data-scroll-target="#w"><span class="header-section-number">23</span> W</a>
  <ul class="collapse">
  <li><a href="#weight-initialization" id="toc-weight-initialization" class="nav-link" data-scroll-target="#weight-initialization"><span class="header-section-number">23.1</span> Weight Initialization</a></li>
  </ul></li>
  <li><a href="#x" id="toc-x" class="nav-link" data-scroll-target="#x"><span class="header-section-number">24</span> X</a>
  <ul class="collapse">
  <li><a href="#xgboost" id="toc-xgboost" class="nav-link" data-scroll-target="#xgboost"><span class="header-section-number">24.1</span> XGBoost</a></li>
  </ul></li>
  <li><a href="#y" id="toc-y" class="nav-link" data-scroll-target="#y"><span class="header-section-number">25</span> Y</a>
  <ul class="collapse">
  <li><a href="#y-axis" id="toc-y-axis" class="nav-link" data-scroll-target="#y-axis"><span class="header-section-number">25.1</span> Y-Axis</a></li>
  </ul></li>
  <li><a href="#z" id="toc-z" class="nav-link" data-scroll-target="#z"><span class="header-section-number">26</span> Z</a>
  <ul class="collapse">
  <li><a href="#z-score" id="toc-z-score" class="nav-link" data-scroll-target="#z-score"><span class="header-section-number">26.1</span> Z-Score</a></li>
  </ul></li>
  </ul>
</nav>
</div>
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Machine Learning de A a Z</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Dr.&nbsp;Fernando Machado Haesbaert </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Pesquisador em Ci√™ncia de Dados - EMBRAPA Pantanal
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<p>Aprendizado de M√°quina (<code>Machine Learning</code>) √© a ci√™ncia que estuda algoritmos e modelos estat√≠sticos que permitem aos computadores realizar tarefas espec√≠ficas sem serem explicitamente programados para isso conceito definido por Arthur Samuel em 1959 <span class="citation" data-cites="ArthurSamuel59">(<a href="#ref-ArthurSamuel59" role="doc-biblioref">Samuel 1959</a>)</span>. Esses sistemas aprendem a partir de dados, identificando padr√µes e fazendo previs√µes com base nesses dados.<br>
O aprendizado de m√°quina √© amplamente utilizado em diversas √°reas, como reconhecimento de voz, vis√£o computacional, recomenda√ß√£o de produtos, an√°lise preditiva e muito mais. Existem diferentes tipos de aprendizado de m√°quina, incluindo aprendizado supervisionado, n√£o supervisionado e por refor√ßo, cada um com suas pr√≥prias t√©cnicas e aplica√ß√µes.<br>
Este gloss√°rio abrange conceitos, termos, algoritmos e t√©cnicas fundamentais em aprendizado de m√°quina, organizados de A a Z. Cada entrada inclui uma breve descri√ß√£o, exemplos em R e refer√™ncias para aprofundamento.</p>
<section id="a" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> A</h1>
<section id="accuracy-acur√°cia" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="accuracy-acur√°cia"><span class="header-section-number">1.1</span> Accuracy (Acur√°cia)</h2>
<p>M√©trica de avalia√ß√£o para problemas de classifica√ß√£o, definida como a propor√ß√£o de previs√µes corretas. Embora simples, costuma ser enganosa em bases desbalanceadas. A acur√°cia √© calculada como: <span class="math display">\[\text{Acur√°cia} = \frac{TP + TN}{TP + TN + FP + FN}\]</span> Onde:<br>
<span class="math inline">\(TP\)</span> s√£o verdadeiros positivos<br>
<span class="math inline">\(TN\)</span> verdadeiros negativos<br>
<span class="math inline">\(FP\)</span> falsos positivos<br>
<span class="math inline">\(FN\)</span> falsos negativos</p>
<section id="exemplo-c√°lculo-da-acur√°cia-em-r" class="level3" data-number="1.1.1">
<h3 data-number="1.1.1" class="anchored" data-anchor-id="exemplo-c√°lculo-da-acur√°cia-em-r"><span class="header-section-number">1.1.1</span> Exemplo: C√°lculo da Acur√°cia em R</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>matriz_confusao <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">47</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(matriz_confusao) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Previsto Positivo"</span>, <span class="st">"Previsto Negativo"</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(matriz_confusao) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Real Positivo"</span>, <span class="st">"Real Negativo"</span>)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizar a matriz de confus√£o </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>matriz_confusao <span class="sc">|&gt;</span> <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span> </span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"Real/Previsto"</span>, <span class="st">"Previsto Positivo"</span>, <span class="st">"Previsto Negativo"</span>),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">caption =</span> <span class="st">"Matriz de Confus√£o"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>  kableExtra<span class="sc">::</span><span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<table class="table caption-top table-sm table-striped small">
<caption>Matriz de Confus√£o</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Real/Previsto</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Previsto Positivo</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Previsto Negativo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Real Positivo</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">2</td>
</tr>
<tr class="even">
<td style="text-align: left;">Real Negativo</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">47</td>
</tr>
</tbody>
</table>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># C√°lculo da Acur√°cia</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>TP <span class="ot">&lt;-</span> matriz_confusao[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>TN <span class="ot">&lt;-</span> matriz_confusao[<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>acuracia <span class="ot">&lt;-</span> (TP <span class="sc">+</span> TN) <span class="sc">/</span> <span class="fu">sum</span>(matriz_confusao)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Acur√°cia:"</span>, <span class="fu">percent</span>(acuracia, <span class="at">accuracy =</span> <span class="fl">0.01</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Acur√°cia: 97.00% </code></pre>
</div>
</div>
<p>Veja mais detalhes em: <span class="citation" data-cites="kuhn13">(<a href="#ref-kuhn13" role="doc-biblioref">Kuhn and Johnson 2013</a>)</span></p>
</section>
</section>
<section id="adaboost-adaptive-boosting" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="adaboost-adaptive-boosting"><span class="header-section-number">1.2</span> AdaBoost (Adaptive Boosting)</h2>
<p>Algoritmo de ensemble baseado em boosting sequencial. Modelos fracos s√£o combinados com pesos adaptativos para reduzir o erro. Cada modelo subsequente foca nos erros do anterior, ajustando pesos das amostras, modelo proposto por <span class="citation" data-cites="freund97">(<a href="#ref-freund97" role="doc-biblioref">Freund and Schapire 1997</a>)</span>.</p>
<section id="exemplo-algoritmo-adaboost-para-classificar-flores-do-conjunto-de-dados-iris." class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="exemplo-algoritmo-adaboost-para-classificar-flores-do-conjunto-de-dados-iris."><span class="header-section-number">1.2.1</span> Exemplo: algoritmo AdaBoost, para classificar flores do conjunto de dados Iris.</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Gera√ß√£o de Dados: Usaremos o conjunto de dados iris</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Dividir em treino e teste</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(iris), <span class="at">size =</span> <span class="fl">0.7</span> <span class="sc">*</span> <span class="fu">nrow</span>(iris))</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>treino <span class="ot">&lt;-</span> iris[id, ]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>teste  <span class="ot">&lt;-</span> iris[<span class="sc">-</span>id, ]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Ajuste do Modelo AdaBoost</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("adabag")</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: pacote 'adabag' foi compilado no R vers√£o 4.4.3</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Carregando pacotes exigidos: doParallel</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Carregando pacotes exigidos: iterators</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Carregando pacotes exigidos: parallel</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">boosting</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> treino)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Avalia√ß√£o</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>previsoes <span class="ot">&lt;-</span> <span class="fu">predict.boosting</span>(modelo, <span class="at">newdata =</span> teste[, <span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Corre√ß√£o: Garante que os n√≠veis sejam id√™nticos</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>previsoes_fator <span class="ot">&lt;-</span> <span class="fu">factor</span>(previsoes<span class="sc">$</span>class, <span class="at">levels =</span> <span class="fu">levels</span>(teste<span class="sc">$</span>Species))</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Matriz de Confus√£o no conjunto de teste</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>confusao_df <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> previsoes_fator,      <span class="co"># Usando a previs√£o corrigida</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">reference =</span> teste<span class="sc">$</span>Species   <span class="co"># Os valores reais</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  confusao_df<span class="sc">$</span>table,</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">caption =</span> <span class="st">"Matriz de Confus√£o - AdaBoost"</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>  kableExtra<span class="sc">::</span><span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<table class="table caption-top table-sm table-striped small">
<caption>Matriz de Confus√£o - AdaBoost</caption>
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: right;" data-quarto-table-cell-role="th">setosa</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">versicolor</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">virginica</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">setosa</td>
<td style="text-align: right;">14</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">versicolor</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="odd">
<td style="text-align: left;">virginica</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">13</td>
</tr>
</tbody>
</table>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. C√°lculo da Acur√°cia</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>acuracia <span class="ot">&lt;-</span> <span class="fu">sum</span>(previsoes_fator <span class="sc">==</span> teste<span class="sc">$</span>Species) <span class="sc">/</span> <span class="fu">nrow</span>(teste)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Acur√°cia do AdaBoost no conjunto iris:"</span>, <span class="fu">percent</span>(acuracia, <span class="at">accuracy =</span> <span class="fl">0.01</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Acur√°cia do AdaBoost no conjunto iris: 97.78% </code></pre>
</div>
</div>
<p>Uma refer√™ncia detalhada √©: <span class="citation" data-cites="hastie09">(<a href="#ref-hastie09" role="doc-biblioref">Hastie, Tibshirani, and Friedman 2009</a>)</span>, este livro √© considerado a b√≠blia do aprendizado de m√°quina e dedica um cap√≠tulo inteiro (Chapter 10: Boosting and Additive Trees) ao conceito de Boosting e ao AdaBoost, explicando-o de forma rigorosa e detalhada, com foco em sua base estat√≠stica e matem√°tica.</p>
</section>
</section>
<section id="aglomerativo-hierarchical-clustering" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="aglomerativo-hierarchical-clustering"><span class="header-section-number">1.3</span> Aglomerativo Hierarchical Clustering</h2>
<p>Fam√≠lia hier√°rquica de m√©todos de agrupamento que unem observa√ß√µes progressivamente. Come√ßa com cada ponto como um cluster individual e funde os mais pr√≥ximos iterativamente, formando uma √°rvore dendrograma de baixo para cima.<br>
Crit√©rios de liga√ß√£o (single, complete, average) definem a dist√¢ncia entre clusters.</p>
<section id="exemplo-em-r-clustering-aglomerativo-com-hclust" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="exemplo-em-r-clustering-aglomerativo-com-hclust"><span class="header-section-number">1.3.1</span> Exemplo em R ‚Äì clustering aglomerativo com hclust:</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>dist_matrix <span class="ot">&lt;-</span> <span class="fu">dist</span>(iris[, <span class="sc">-</span><span class="dv">5</span>]) </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>hc <span class="ot">&lt;-</span> <span class="fu">hclust</span>(dist_matrix, <span class="at">method =</span> <span class="st">"complete"</span>) </span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc) <span class="co"># Dendrograma</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Machine_Learning_A_a_Z_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Veja o metodo contr√°rio a esse , o <a href="#divisive_hierarchical_clustering">Divisive Hierarchical Clustering</a>.</p>
</section>
</section>
<section id="aic-akaike-information-criterion-crit√©rio-de-akaike" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="aic-akaike-information-criterion-crit√©rio-de-akaike"><span class="header-section-number">1.4</span> AIC ‚Äì Akaike Information Criterion (Crit√©rio de Akaike)</h2>
<p>√çndice de sele√ß√£o de modelos usado amplamente em modelos estat√≠sticos e regress√µes generalizadas. Baseia-se na teoria da informa√ß√£o, penalizando a complexidade do modelo para evitar overfitting.<br>
Calculado como: <span class="math display">\[\text{AIC} = 2k - 2\ln(L)\]</span><br>
Onde: <span class="math inline">\(k\)</span> √© o n√∫mero de par√¢metros do modelo e <span class="math inline">\(L\)</span> √© a verossimilhan√ßa m√°xima do modelo.<br>
Modelos com menor AIC s√£o preferidos.</p>
<section id="exemplo-compara√ß√£o-de-modelos-lineares-com-aic" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="exemplo-compara√ß√£o-de-modelos-lineares-com-aic"><span class="header-section-number">1.4.1</span> Exemplo: compara√ß√£o de modelos lineares com AIC:</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Repare que removi os sinais de "+" que indicam quebra de linha no console</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>( </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>),</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Aqui o tibble permite chamar o x1 criado na linha acima</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="dv">2</span>), </span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x3 =</span> x2 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="dv">3</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>x1 <span class="sc">-</span> <span class="fl">1.5</span><span class="sc">*</span>x2 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x3 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">2</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(df)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>          x1        x2        x3         y
x1 1.0000000 0.7812880 0.6615495 0.5662511
x2 0.7812880 1.0000000 0.8382767 0.1131372
x3 0.6615495 0.8382767 1.0000000 0.2344350
y  0.5662511 0.1131372 0.2344350 1.0000000</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> df) </span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> df) </span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>aic_values <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model1, model2) </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(aic_values)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>       df      AIC
model1  4 452.5927
model2  5 438.9226</code></pre>
</div>
</div>
</section>
</section>
<section id="artificial-neural-networks-anns" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="artificial-neural-networks-anns"><span class="header-section-number">1.5</span> Artificial Neural Networks (ANNs)</h2>
<p>S√£o sistemas de computa√ß√£o inspirados na arquitetura de neur√¥nios biol√≥gicos, formalizados como composi√ß√µes de fun√ß√µes n√£o-lineares <span class="math inline">\(Œ∏(ùêñùê± + ùêõ)\)</span>, onde <span class="math inline">\(ùêñ\)</span> denota matrizes de pesos sin√°pticos, <span class="math inline">\(Œ∏\)</span> √© uma fun√ß√£o de ativa√ß√£o (ReLU, sigm√≥ide, tanh) e <span class="math inline">\(b\)</span> vi√©s (bias) . A capacidade de aproximadores universais (HORNIK et al., 1989) garante que ANNs com uma camada oculta suficientemente larga podem modelar qualquer fun√ß√£o cont√≠nua em dom√≠nio compacto.<br>
Refer√™ncia: <span class="citation" data-cites="hornik89">(<a href="#ref-hornik89" role="doc-biblioref">Hornik 1989</a>)</span>.</p>
<section id="exemplo-em-r-rede-feed-forward-para-regress√£o-com-pacote-nnet" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="exemplo-em-r-rede-feed-forward-para-regress√£o-com-pacote-nnet"><span class="header-section-number">1.5.1</span> Exemplo em R: Rede feed-forward para regress√£o com pacote <code>{nnet}</code></h3>
<p>A rede feed-forward √© um tipo de rede neural artificial onde as conex√µes entre os n√≥s n√£o formam ciclos. Ela √© amplamente utilizada para tarefas de regress√£o e classifica√ß√£o. No R, o pacote <code>{nnet}</code> oferece uma maneira simples de implementar redes feed-forward.</p>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Gera√ß√£o de Dados N√ÉO-LINEARES: Redes neurais brilham onde a linearidade falha. </span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Vamos criar uma fun√ß√£o seno com ru√≠do.</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, <span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># Valores entre 0 e 10</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x) <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">sd =</span> <span class="fl">0.2</span>) <span class="co"># Seno + ru√≠do</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>dados <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Separa√ß√£o Treino/Teste (Boas pr√°ticas)</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="at">size =</span> <span class="fl">0.8</span> <span class="sc">*</span> N)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>treino <span class="ot">&lt;-</span> dados[indices, ]</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>teste  <span class="ot">&lt;-</span> dados[<span class="sc">-</span>indices, ]</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Ajuste do Modelo (Regress√£o)</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co"># size: neur√¥nios na camada oculta</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co"># linout = TRUE: essencial para regress√£o (sa√≠da linear, n√£o sigmoide)</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>modelo_ann <span class="ot">&lt;-</span> <span class="fu">nnet</span>(y <span class="sc">~</span> x, </span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> treino, </span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>                   <span class="at">size =</span> <span class="dv">10</span>, </span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>                   <span class="at">linout =</span> <span class="cn">TRUE</span>, </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>                   <span class="at">decay =</span> <span class="fl">0.001</span>, </span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>                   <span class="at">maxit =</span> <span class="dv">1000</span>, </span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trace =</span> <span class="cn">FALSE</span>) <span class="co"># trace=FALSE limpa o console</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Avalia√ß√£o</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>previsoes <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo_ann, teste)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># C√°lculo do Erro Quadr√°tico M√©dio (MSE)</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> <span class="fu">mean</span>((teste<span class="sc">$</span>y <span class="sc">-</span> previsoes)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Erro Quadr√°tico M√©dio (MSE) no teste:"</span>, <span class="fu">round</span>(mse, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Erro Quadr√°tico M√©dio (MSE) no teste: 0.0454 </code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualiza√ß√£o </span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Prepara√ß√£o: Adicionar as previs√µes ao data frame de teste</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>dados_plot <span class="ot">&lt;-</span> teste <span class="sc">%&gt;%</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">predito =</span> previsoes)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Visualiza√ß√£o</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dados_plot, <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Camada dos dados REAIS</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Note que definimos color="Real" DENTRO do aes() para criar a legenda</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">color =</span> <span class="st">"Real"</span>, <span class="at">shape =</span> <span class="st">"Real"</span>), </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="dv">2</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Camada dos dados PREVISTOS</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> predito, <span class="at">color =</span> <span class="st">"Previsto"</span>, <span class="at">shape =</span> <span class="st">"Previsto"</span>), </span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="dv">3</span>, <span class="at">stroke =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Personaliza√ß√£o manual para imitar o estilo do R Base (cinza/vermelho e c√≠rculo/x)</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">"Legenda"</span>, </span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>                     <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Real"</span> <span class="ot">=</span> <span class="st">"gray"</span>, <span class="st">"Previsto"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_shape_manual</span>(<span class="at">name =</span> <span class="st">"Legenda"</span>, </span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>                     <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Real"</span> <span class="ot">=</span> <span class="dv">19</span>, <span class="st">"Previsto"</span> <span class="ot">=</span> <span class="dv">4</span>)) <span class="sc">+</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># T√≠tulos e Tema</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"ANN: Ajuste a Fun√ß√£o Seno"</span>,</span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Compara√ß√£o entre dados reais e aproxima√ß√£o da rede neural"</span>,</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Valor de Y"</span>,</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Valor de X"</span>) <span class="sc">+</span></span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Machine_Learning_A_a_Z_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="b" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> B</h1>
<section id="bagging-bootstrap-aggregating" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="bagging-bootstrap-aggregating"><span class="header-section-number">2.1</span> Bagging (Bootstrap Aggregating)</h2>
<p>Proposto por Breiman (1996), reduz vari√¢ncia ao treinar modelos em m√∫ltiplas amostras bootstrap e agregar predi√ß√µes por vota√ß√£o majorit√°ria (classifica√ß√£o) ou m√©dia (regress√£o). A de-correla√ß√£o entre √°rvores √© cr√≠tica para ganhos de precis√£o. Exemplo em R ‚Äì floresta aleat√≥ria com randomForest: r Copy library(randomForest) rf &lt;- randomForest(Species ~ ., data = iris, ntree = 1000, importance = TRUE) print(rf$err.rate[1000, ‚ÄúOOB‚Äù]) Refer√™ncia: Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2), 123-140.</p>
</section>
</section>
<section id="c" class="level1" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> C</h1>
<section id="cross-validation-cv" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="cross-validation-cv"><span class="header-section-number">3.1</span> Cross-Validation (CV)</h2>
<p>Estimador de erro de generaliza√ß√£o com vi√©s‚Äìvari√¢ncia controlado. O k-fold CV particiona os dados em k subconjuntos mutuamente exclusivos; cada parti√ß√£o √© usada uma vez como teste. O nested CV √© obrigat√≥rio quando h√° sintonia de hiper-par√¢metros para evitar otimismo de desempenho (Cawley &amp; Talbot, 2010). Exemplo em R ‚Äì valida√ß√£o cruzada aninhada com caret: r Copy library(caret) tc &lt;- trainControl(method = ‚Äúrepeatedcv‚Äù, number = 10, repeats = 5, search = ‚Äúgrid‚Äù) fit &lt;- train(Class ~ ., data = Sonar, method = ‚ÄúsvmRadial‚Äù, tuneLength = 15, trControl = tc) Refer√™ncia: Cawley, G. C. &amp; Talbot, N. L. C. (2010). On over-fitting in model selection and subsequent selection bias in performance evaluation. JMLR, 11, 2079-2107.</p>
</section>
</section>
<section id="d" class="level1" data-number="4">
<h1 data-number="4"><span class="header-section-number">4</span> D</h1>
<section id="decision-trees-√°rvores-de-decis√£o" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="decision-trees-√°rvores-de-decis√£o"><span class="header-section-number">4.1</span> Decision Trees (√Årvores de Decis√£o)</h2>
<p>Modelos simb√≥licos que particionam recursivamente o espa√ßo de preditores via medidas de impureza (Gini, entropia ou erro de classifica√ß√£o). A complexidade √© controlada por poda cost-complexity (cp) ou restri√ß√µes de profundidade. Exemplo em R ‚Äì √°rvore CART com rpart: r Copy library(rpart) arvore &lt;- rpart(Kyphosis ~ Age + Number + Start, data = kyphosis, method = ‚Äúclass‚Äù, cp = 0.01) rpart.plot::rpart.plot(arvore)</p>
</section>
<section id="divisive_hierarchical_clustering" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="divisive_hierarchical_clustering"><span class="header-section-number">4.2</span> Divisive Hierarchical Clustering</h2>
<p>Um m√©todo de agrupamento hier√°rquico divisivo emprega uma estrat√©gia de cima para baixo. Ele come√ßa colocando todos os objetos em um cluster, que √© a raiz da hierarquia. Em seguida, divide o cluster raiz em v√°rios subclusters menores e particiona recursivamente esses clusters em clusters menores. O processo de particionamento continua at√© que cada objeto esteja em seu pr√≥prio cluster ou at√© que um crit√©rio de parada seja atendido (por exemplo, n√∫mero desejado de clusters ou dist√¢ncia m√≠nima entre clusters).</p>
<section id="exemplo-em-r-clustering-divisivo-com-diana" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="exemplo-em-r-clustering-divisivo-com-diana"><span class="header-section-number">4.2.1</span> Exemplo em R ‚Äì clustering divisivo com diana</h3>
<div class="cell">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster) </span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: pacote 'cluster' foi compilado no R vers√£o 4.4.3</code></pre>
</div>
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris) </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>div_clust <span class="ot">&lt;-</span> <span class="fu">diana</span>(iris[, <span class="sc">-</span><span class="dv">5</span>]) </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(div_clust) <span class="co"># Dendrograma</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Machine_Learning_A_a_Z_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="Machine_Learning_A_a_Z_files/figure-html/unnamed-chunk-7-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="e" class="level1" data-number="5">
<h1 data-number="5"><span class="header-section-number">5</span> E</h1>
<section id="ensemble-learning" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="ensemble-learning"><span class="header-section-number">5.1</span> Ensemble Learning</h2>
<p>Princ√≠pio de combinar preditores fracos para formar um preditor forte. Al√©m de bagging e boosting, stacking (Wolpert, 1992) usa um meta-modelo para ponderar especialistas de base. Diverg√™ncia entre componentes √© essencial (Kuncheva &amp; Whitaker, 2003). Exemplo em R ‚Äì stacking com SuperLearner: r Copy library(SuperLearner) SL.library &lt;- c(‚ÄúSL.glm‚Äù, ‚ÄúSL.ranger‚Äù, ‚ÄúSL.xgboost‚Äù) fitSL &lt;- SuperLearner(Y = y, X = X, SL.library = SL.library, family = binomial())</p>
</section>
</section>
<section id="f" class="level1" data-number="6">
<h1 data-number="6"><span class="header-section-number">6</span> F</h1>
<section id="feature-scaling" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="feature-scaling"><span class="header-section-number">6.1</span> Feature Scaling</h2>
<p>Muitos algoritmos (SVM, redes neurais, k-NN) s√£o sens√≠veis √† magnitude das vari√°veis. A padroniza√ß√£o z-score (Œº = 0, œÉ = 1) ou normaliza√ß√£o min-max [0, 1] garante converg√™ncia num√©rica e interpretabilidade de penalidades regulares. Exemplo em R ‚Äì pipeline com recipes: r Copy library(recipes) receita &lt;- recipe(y ~ ., data = df) %&gt;% step_normalize(all_numeric_predictors()) %&gt;% prep() df_scaled &lt;- bake(receita, new_data = NULL)</p>
</section>
</section>
<section id="g" class="level1" data-number="7">
<h1 data-number="7"><span class="header-section-number">7</span> G</h1>
<section id="gradient-descent-gd" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="gradient-descent-gd"><span class="header-section-number">7.1</span> Gradient Descent (GD)</h2>
<p>Algoritmo de otimiza√ß√£o de primeira ordem que atualiza par√¢metros na dire√ß√£o oposta ao gradiente da fun√ß√£o de perda. GD estoc√°stico (SGD) reduz custo computacional por amostras mini-batch; adaptativos (Adam, RMSprop) ajustam taxas de aprendizado por momentos. Exemplo em R ‚Äì GD manual para regress√£o linear: r Copy gd &lt;- function(X, y, lr = 0.01, epochs = 1000) { beta &lt;- rep(0, ncol(X)) for(i in 1:epochs) { grad &lt;- -2 * t(X) %<em>% (y - X %</em>% beta) / nrow(X) beta &lt;- beta - lr * grad } beta }</p>
</section>
</section>
<section id="h" class="level1" data-number="8">
<h1 data-number="8"><span class="header-section-number">8</span> H</h1>
<section id="hyperparameter-tuning" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="hyperparameter-tuning"><span class="header-section-number">8.1</span> Hyperparameter Tuning</h2>
<p>Espa√ßo de configura√ß√µes externas ao modelo (n√∫mero de vizinhos, C de SVM, profundidade de √°rvore) √© otimizado via busca em grade, aleat√≥ria (Bergstra &amp; Bengio, 2012) ou bayesiana (TPE, Gaussian Process). Exemplo em R ‚Äì bayesiano com mlr3tuning: r Copy library(mlr3tuning) task &lt;- tsk(‚Äúsonar‚Äù) learner &lt;- lrn(‚Äúclassif.svm‚Äù, type = ‚ÄúC-classification‚Äù, kernel = ‚Äúradial‚Äù) search_space &lt;- ps(C = p_dbl(1e-1, 1e3), sigma = p_dbl(1e-4, 1)) tuner &lt;- tnr(‚Äúmbo‚Äù, n_evals = 30)</p>
</section>
</section>
<section id="i" class="level1" data-number="9">
<h1 data-number="9"><span class="header-section-number">9</span> I</h1>
<section id="instance-based-learning" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="instance-based-learning"><span class="header-section-number">9.1</span> Instance-Based Learning</h2>
<p>Fam√≠lia de algoritmos que adiam generaliza√ß√£o at√© o momento da predi√ß√£o, armazenando exemplos (k-NN, kernel regression). A complexidade de predi√ß√£o √© O(n), exigindo estruturas de indexa√ß√£o (KD-tree, ball-tree) ou proje√ß√µes de baixa dimensionalidade. Exemplo em R ‚Äì k-NN com FNN: r Copy library(FNN) knn_pred &lt;- knn.reg(train = treino[, -1], test = teste[, -1], y = treino$y, k = 5)</p>
</section>
</section>
<section id="j" class="level1" data-number="10">
<h1 data-number="10"><span class="header-section-number">10</span> J</h1>
<section id="jaccard-index" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="jaccard-index"><span class="header-section-number">10.1</span> Jaccard Index</h2>
<p>Medida de similaridade de conjuntos J(A,B) = |A ‚à© B| / |A ‚à™ B|. √ötil em dados bin√°rios (presen√ßa/aus√™ncia) ou comunidades em grafos. Exemplo em R: r Copy jaccard &lt;- function(a, b) { length(intersect(a, b)) / length(union(a, b)) }</p>
</section>
</section>
<section id="k" class="level1" data-number="11">
<h1 data-number="11"><span class="header-section-number">11</span> K</h1>
<section id="k-nearest-neighbors-knn" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="k-nearest-neighbors-knn"><span class="header-section-number">11.1</span> K-Nearest Neighbors (KNN)</h2>
<p>Classificador n√£o-param√©trico que atribui classe majorit√°ria entre os k vizinhos mais pr√≥ximos. A escolha de k via CV balancea vi√©s‚Äìvari√¢ncia; dist√¢ncias ponderadas (IDW) reduzem influ√™ncia de vizinhos distantes. Exemplo em R ‚Äì tuning de k: r Copy library(caret) fit &lt;- train(Class ~ ., data = Sonar, method = ‚Äúknn‚Äù, tuneGrid = data.frame(k = seq(1, 25, by = 2)))</p>
</section>
</section>
<section id="l" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> L</h1>
<section id="logistic-regression" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="logistic-regression"><span class="header-section-number">12.1</span> Logistic Regression</h2>
<p>Modelo linear generalizado com fun√ß√£o de liga√ß√£o logit, garantindo probabilidades em [0, 1]. A interpreta√ß√£o via odds-ratio √© cl√°ssica em epidemiologia. Regulariza√ß√£o L1 (lasso) permite sele√ß√£o de vari√°veis. Exemplo em R ‚Äì regress√£o log√≠stica com glmnet: r Copy library(glmnet) cvfit &lt;- cv.glmnet(x = x, y = y, family = ‚Äúbinomial‚Äù, alpha = 1) coef(cvfit, s = ‚Äúlambda.min‚Äù)</p>
</section>
</section>
<section id="m" class="level1" data-number="13">
<h1 data-number="13"><span class="header-section-number">13</span> M</h1>
<section id="model-overfitting" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="model-overfitting"><span class="header-section-number">13.1</span> Model Overfitting</h2>
<p>Situa√ß√£o emindo a fun√ß√£o de risco emp√≠rico ‚â™ risco verdadeiro, indicando captura de ru√≠do. Diagn√≥stico via curva de valida√ß√£o (training √ó validation loss) ou complexidade VC. Solu√ß√µes: penaliza√ß√£o, early stopping, aumento de dados. Refer√™ncia: Vapnik, V. (1998). Statistical Learning Theory. Wiley.</p>
</section>
</section>
<section id="n" class="level1" data-number="14">
<h1 data-number="14"><span class="header-section-number">14</span> N</h1>
<section id="normalization" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="normalization"><span class="header-section-number">14.1</span> Normalization</h2>
<p>Transforma√ß√£o que reescala vari√°veis para intervalo fixo, comum em redes neurais. A normaliza√ß√£o por lote (batch norm) acelera converg√™ncia reduzindo covari√¢ncia interna (Ioffe &amp; Szegedy, 2015). Exemplo em R ‚Äì batch norm em keras: r Copy library(keras) model %&gt;% layer_batch_normalization()</p>
</section>
</section>
<section id="o" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> O</h1>
<section id="outliers" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="outliers"><span class="header-section-number">15.1</span> Outliers</h2>
<p>Observa√ß√µes que violam pressuposto de distribui√ß√£o cont√≠nua ou homocedasticidade. Detectados via dist√¢ncia de Mahalanobis, LOF ou Isolation Forest. Em modelos lineares, leverage e Cook‚Äôs D quantificam influ√™ncia. Exemplo em R: r Copy library(isotree) iso &lt;- isolation.forest(df, ntrees = 500) scores &lt;- predict(iso, df)</p>
</section>
</section>
<section id="p" class="level1" data-number="16">
<h1 data-number="16"><span class="header-section-number">16</span> P</h1>
<section id="principal-component-analysis-pca" class="level2" data-number="16.1">
<h2 data-number="16.1" class="anchored" data-anchor-id="principal-component-analysis-pca"><span class="header-section-number">16.1</span> Principal Component Analysis (PCA)</h2>
<p>Decomposi√ß√£o ortogonal que maximiza vari√¢ncia projetada, equivalente √† decomposi√ß√£o em valores singulares (SVD) da matriz centrada. PCA √© usada para visualiza√ß√£o, ru√≠do filtrado e redu√ß√£o de dimensionalidade antes de algoritmos pesados. Exemplo em R: r Copy pca &lt;- prcomp(df, center = TRUE, scale. = TRUE) biplot(pca)</p>
</section>
</section>
<section id="q" class="level1" data-number="17">
<h1 data-number="17"><span class="header-section-number">17</span> Q</h1>
<section id="q-learning" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="q-learning"><span class="header-section-number">17.1</span> Q-Learning</h2>
<p>Algoritmo de aprendizado por refor√ßo off-policy que estima fun√ß√£o Q*(s,a) via atualiza√ß√£o de Bellman. A converg√™ncia √© garantida sob visita√ß√£o infinita de pares (s,a) com taxa de aprendizado decrescente. Exemplo em R ‚Äì pacote ReinforcementLearning: r Copy library(ReinforcementLearning) data(‚Äúgridworld‚Äù) model &lt;- ReinforcementLearning(data = gridworld, s = ‚Äústate‚Äù, a = ‚Äúaction‚Äù, r = ‚Äúreward‚Äù, s_new = ‚Äúnext_state‚Äù)</p>
</section>
</section>
<section id="r" class="level1" data-number="18">
<h1 data-number="18"><span class="header-section-number">18</span> R</h1>
<section id="regularization" class="level2" data-number="18.1">
<h2 data-number="18.1" class="anchored" data-anchor-id="regularization"><span class="header-section-number">18.1</span> Regularization</h2>
<p>T√©cnica que adiciona penalidade Œ©(Œ≤) √† fun√ß√£o de perda, impondo trade-off vi√©s‚Äìvari√¢ncia. Ridge (L2) encolhe coeficientes, lasso (L1) promove esparsidade, elastic-net combina ambas. Exemplo em R ‚Äì elastic-net com glmnet: r Copy cvfit &lt;- cv.glmnet(x, y, alpha = 0.5) # 0.5 = elastic-net</p>
</section>
</section>
<section id="s" class="level1" data-number="19">
<h1 data-number="19"><span class="header-section-number">19</span> S</h1>
<section id="support-vector-machines-svm" class="level2" data-number="19.1">
<h2 data-number="19.1" class="anchored" data-anchor-id="support-vector-machines-svm"><span class="header-section-number">19.1</span> Support Vector Machines (SVM)</h2>
<p>Classificador de margem m√°xima que resolve problema de otimiza√ß√£o quadr√°tica convexo. O kernel trick permite espa√ßos de Hilbert de alta dimens√£o sem custo computacional expl√≠cito. Exemplo em R ‚Äì SVM radial com e1071: r Copy library(e1071) fit &lt;- svm(Class ~ ., data = treino, kernel = ‚Äúradial‚Äù, cost = 10, gamma = 0.1)</p>
</section>
</section>
<section id="t" class="level1" data-number="20">
<h1 data-number="20"><span class="header-section-number">20</span> T</h1>
<section id="training-set" class="level2" data-number="20.1">
<h2 data-number="20.1" class="anchored" data-anchor-id="training-set"><span class="header-section-number">20.1</span> Training Set</h2>
<p>Conjunto de dados usado para estimar par√¢metros do modelo. Deve ser representativo da popula√ß√£o; t√©cnicas de amostragem estratificada preservam propor√ß√µes de classe. O tamanho ideal depende da taxa de cobertura do espa√ßo de caracter√≠sticas (Cover &amp; Hart, 1967).</p>
</section>
</section>
<section id="u" class="level1" data-number="21">
<h1 data-number="21"><span class="header-section-number">21</span> U</h1>
<section id="underfitting" class="level2" data-number="21.1">
<h2 data-number="21.1" class="anchored" data-anchor-id="underfitting"><span class="header-section-number">21.1</span> Underfitting</h2>
<p>Modelo com capacidade insuficiente (alto vi√©s) n√£o captura estrutura dos dados. Indicado por erro de treino elevado. Solu√ß√µes: aumentar complexidade, adicionar features, reduzir regulariza√ß√£o.</p>
</section>
</section>
<section id="v" class="level1" data-number="22">
<h1 data-number="22"><span class="header-section-number">22</span> V</h1>
<section id="validation-set" class="level2" data-number="22.1">
<h2 data-number="22.1" class="anchored" data-anchor-id="validation-set"><span class="header-section-number">22.1</span> Validation Set</h2>
<p>Dados separados do treino para ajuste de hiper-par√¢metros, evitando vazamento de informa√ß√£o. Em datasets pequenos, cross-validation interno √© prefer√≠vel.</p>
</section>
</section>
<section id="w" class="level1" data-number="23">
<h1 data-number="23"><span class="header-section-number">23</span> W</h1>
<section id="weight-initialization" class="level2" data-number="23.1">
<h2 data-number="23.1" class="anchored" data-anchor-id="weight-initialization"><span class="header-section-number">23.1</span> Weight Initialization</h2>
<p>Valores iniciais influenciam converg√™ncia e qualidade de m√≠nimo. Xavier/Glorot idealiza vari√¢ncia 2/(fan_in + fan_out) para sigm√≥ides; He inicializa com 2/fan_in para ReLU. Exemplo em R ‚Äì inicializa√ß√£o He no keras: r Copy layer_dense(units = 128, activation = ‚Äúrelu‚Äù, kernel_initializer = ‚Äúhe_normal‚Äù)</p>
</section>
</section>
<section id="x" class="level1" data-number="24">
<h1 data-number="24"><span class="header-section-number">24</span> X</h1>
<section id="xgboost" class="level2" data-number="24.1">
<h2 data-number="24.1" class="anchored" data-anchor-id="xgboost"><span class="header-section-number">24.1</span> XGBoost</h2>
<p>Implementa√ß√£o escalon√°vel de gradient boosting comÁ®ÄÁñèÊï∞ÊçÆ (sparsity-aware), regulariza√ß√£o L1/L2 em √°rvores, e paraleliza√ß√£o porÁâπÂæÅÂàÜÂùó. Domina competi√ß√µes tabulares. Exemplo em R: r Copy library(xgboost) dtrain &lt;- xgb.DMatrix(data = as.matrix(treino[, -1]), label = treino$label) param &lt;- list(max_depth = 6, eta = 0.05, subsample = 0.8, colsample_bytree = 0.8, objective = ‚Äúbinary:logistic‚Äù) bst &lt;- xgb.train(param, dtrain, nrounds = 400, watchlist = list(train = dtrain), early_stopping_rounds = 10)</p>
</section>
</section>
<section id="y" class="level1" data-number="25">
<h1 data-number="25"><span class="header-section-number">25</span> Y</h1>
<section id="y-axis" class="level2" data-number="25.1">
<h2 data-number="25.1" class="anchored" data-anchor-id="y-axis"><span class="header-section-number">25.1</span> Y-Axis</h2>
<p>Nos gr√°ficos de curvas de aprendizado, representa m√©trica de desempenho (acur√°cia, AUC, RMSE) ou erro emp√≠rico. A an√°lise de gap entre treino e valida√ß√£o revela overfitting/underfitting.</p>
</section>
</section>
<section id="z" class="level1" data-number="26">
<h1 data-number="26"><span class="header-section-number">26</span> Z</h1>
<section id="z-score" class="level2" data-number="26.1">
<h2 data-number="26.1" class="anchored" data-anchor-id="z-score"><span class="header-section-number">26.1</span> Z-Score</h2>
<p>Escore padronizado z = (x ‚àí Œº)/œÉ, indicando desvios em unidades de desvio-padr√£o. Utilizado para detec√ß√£o de outliers (|z| &gt; 3) e normaliza√ß√£o de features. Exemplo em R: r Copy z &lt;- scale(df$x)</p>
<p>Refer√™ncias gerais</p>
<p>Bergstra, J. &amp; Bengio, Y. (2012). Random search for hyper-parameter optimization. JMLR, 13, 281-305.</p>
<p>Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5-32.</p>
<p>Cover, T. &amp; Hart, P. (1967). Nearest neighbor pattern classification. IEEE TIT, 13(1), 21-27.</p>
<p>Ioffe, S. &amp; Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. ICML.</p>
<!-- -->


</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-freund97" class="csl-entry" role="listitem">
Freund, Yoav, and Robert E Schapire. 1997. <span>‚ÄúA Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting.‚Äù</span> <em>Journal of Computer and System Sciences</em> 55 (1): 119‚Äì39.
</div>
<div id="ref-hastie09" class="csl-entry" role="listitem">
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. 2nd ed. Springer. <a href="https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf">https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf</a>.
</div>
<div id="ref-hornik89" class="csl-entry" role="listitem">
Hornik, M.; White, K.; Stinchcombe. 1989. <span>‚ÄúMultilayer Feedforward Networks Are Universal Approximators.‚Äù</span> <em>Neural Networks</em> 2 (5): 359‚Äì66.
</div>
<div id="ref-kuhn13" class="csl-entry" role="listitem">
Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. Springer. <a href="https://vuquangnguyen2016.wordpress.com/wp-content/uploads/2018/03/applied-predictive-modeling-max-kuhn-kjell-johnson_1518.pdf">https://vuquangnguyen2016.wordpress.com/wp-content/uploads/2018/03/applied-predictive-modeling-max-kuhn-kjell-johnson_1518.pdf</a>.
</div>
<div id="ref-ArthurSamuel59" class="csl-entry" role="listitem">
Samuel, A. L. 1959. <span>‚ÄúSome Studies in Machine Learning Using the Game of Checkers.‚Äù</span> <em>IBM Journal of Research and Development</em> 3 (3): 210‚Äì29. <a href="https://doi.org/10.1147/rd.33.0210">https://doi.org/10.1147/rd.33.0210</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "Óßã";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb23" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Machine Learning de A a Z"</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: "Dr. Fernando Machado Haesbaert"</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">    affiliation: "Pesquisador em Ci√™ncia de Dados - EMBRAPA Pantanal"</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-style:</span><span class="co"> default</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="an">title-block-banner:</span><span class="co"> false</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-location: left</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">    number-sections: true</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co">    theme: cosmo</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="co">    df-print: paged</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: true</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a><span class="co">    code-tools: true</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a><span class="co">    highlight-style: github</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a><span class="co">    smooth-scroll: true</span></span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a><span class="an">editor:</span><span class="co"> visual</span></span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a><span class="an">bibliography:</span><span class="co"> referencias.bib</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>Aprendizado de M√°quina (<span class="in">`Machine Learning`</span>) √© a ci√™ncia que estuda algoritmos e modelos estat√≠sticos que permitem aos computadores realizar tarefas espec√≠ficas sem serem explicitamente programados para isso conceito definido por Arthur Samuel em 1959 <span class="co">[</span><span class="ot">@ArthurSamuel59</span><span class="co">]</span>. Esses sistemas aprendem a partir de dados, identificando padr√µes e fazendo previs√µes com base nesses dados.\</span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>O aprendizado de m√°quina √© amplamente utilizado em diversas √°reas, como reconhecimento de voz, vis√£o computacional, recomenda√ß√£o de produtos, an√°lise preditiva e muito mais. Existem diferentes tipos de aprendizado de m√°quina, incluindo aprendizado supervisionado, n√£o supervisionado e por refor√ßo, cada um com suas pr√≥prias t√©cnicas e aplica√ß√µes.\</span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>Este gloss√°rio abrange conceitos, termos, algoritmos e t√©cnicas fundamentais em aprendizado de m√°quina, organizados de A a Z. Cada entrada inclui uma breve descri√ß√£o, exemplos em R e refer√™ncias para aprofundamento.</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Pacotes utilizados nos chunks</span></span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>pkgs <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"nnet"</span>, <span class="st">"randomForest"</span>, <span class="st">"caret"</span>, <span class="st">"rpart"</span>, <span class="st">"rpart.plot"</span>, <span class="st">"SuperLearner"</span>, </span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>          <span class="st">"FNN"</span>, <span class="st">"glmnet"</span>, <span class="st">"e1071"</span>, <span class="st">"xgboost"</span>, <span class="st">"recipes"</span>, <span class="st">"isotree"</span>, <span class="st">"keras"</span>, </span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>          <span class="st">"mlr3tuning"</span>, <span class="st">"ReinforcementLearning"</span>, <span class="st">"scales"</span>)</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">lapply</span>(pkgs, \(p) <span class="cf">if</span> (<span class="sc">!</span><span class="fu">requireNamespace</span>(p, <span class="at">quietly =</span> <span class="cn">TRUE</span>)) <span class="fu">install.packages</span>(p)))</span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span class="fu">lapply</span>(pkgs, library, <span class="at">character.only =</span> <span class="cn">TRUE</span>)</span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a><span class="fu"># A</span></span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a><span class="fu">## Accuracy (Acur√°cia)</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a>M√©trica de avalia√ß√£o para problemas de classifica√ß√£o, definida como a propor√ß√£o de previs√µes corretas. Embora simples, costuma ser enganosa em bases desbalanceadas. A acur√°cia √© calculada como: $$\text{Acur√°cia} = \frac{TP + TN}{TP + TN + FP + FN}$$ Onde:\</span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>$TP$ s√£o verdadeiros positivos\</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a>$TN$ verdadeiros negativos\</span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a>$FP$ falsos positivos\</span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a>$FN$ falsos negativos</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exemplo: C√°lculo da Acur√°cia em R</span></span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a>matriz_confusao <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">47</span>), <span class="at">nrow =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(matriz_confusao) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Previsto Positivo"</span>, <span class="st">"Previsto Negativo"</span>)</span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(matriz_confusao) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Real Positivo"</span>, <span class="st">"Real Negativo"</span>)</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualizar a matriz de confus√£o </span></span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>matriz_confusao <span class="sc">|&gt;</span> <span class="fu">as.data.frame</span>() <span class="sc">|&gt;</span> </span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"Real/Previsto"</span>, <span class="st">"Previsto Positivo"</span>, <span class="st">"Previsto Negativo"</span>),</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a>               <span class="at">caption =</span> <span class="st">"Matriz de Confus√£o"</span>) <span class="sc">|&gt;</span> </span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a>  kableExtra<span class="sc">::</span><span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a><span class="co"># C√°lculo da Acur√°cia</span></span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a>TP <span class="ot">&lt;-</span> matriz_confusao[<span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a>TN <span class="ot">&lt;-</span> matriz_confusao[<span class="dv">2</span>, <span class="dv">2</span>]</span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>acuracia <span class="ot">&lt;-</span> (TP <span class="sc">+</span> TN) <span class="sc">/</span> <span class="fu">sum</span>(matriz_confusao)</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Acur√°cia:"</span>, <span class="fu">percent</span>(acuracia, <span class="at">accuracy =</span> <span class="fl">0.01</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>Veja mais detalhes em: <span class="co">[</span><span class="ot">@kuhn13</span><span class="co">]</span></span>
<span id="cb23-76"><a href="#cb23-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-77"><a href="#cb23-77" aria-hidden="true" tabindex="-1"></a><span class="fu">## AdaBoost (Adaptive Boosting)</span></span>
<span id="cb23-78"><a href="#cb23-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-79"><a href="#cb23-79" aria-hidden="true" tabindex="-1"></a>Algoritmo de ensemble baseado em boosting sequencial. Modelos fracos s√£o combinados com pesos adaptativos para reduzir o erro. Cada modelo subsequente foca nos erros do anterior, ajustando pesos das amostras, modelo proposto por <span class="co">[</span><span class="ot">@freund97</span><span class="co">]</span>.</span>
<span id="cb23-80"><a href="#cb23-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-81"><a href="#cb23-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exemplo: algoritmo AdaBoost, para classificar flores do conjunto de dados Iris.</span></span>
<span id="cb23-82"><a href="#cb23-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-85"><a href="#cb23-85" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-86"><a href="#cb23-86" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb23-87"><a href="#cb23-87" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Gera√ß√£o de Dados: Usaremos o conjunto de dados iris</span></span>
<span id="cb23-88"><a href="#cb23-88" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span>
<span id="cb23-89"><a href="#cb23-89" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Dividir em treino e teste</span></span>
<span id="cb23-90"><a href="#cb23-90" aria-hidden="true" tabindex="-1"></a>id <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(iris), <span class="at">size =</span> <span class="fl">0.7</span> <span class="sc">*</span> <span class="fu">nrow</span>(iris))</span>
<span id="cb23-91"><a href="#cb23-91" aria-hidden="true" tabindex="-1"></a>treino <span class="ot">&lt;-</span> iris[id, ]</span>
<span id="cb23-92"><a href="#cb23-92" aria-hidden="true" tabindex="-1"></a>teste  <span class="ot">&lt;-</span> iris[<span class="sc">-</span>id, ]</span>
<span id="cb23-93"><a href="#cb23-93" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Ajuste do Modelo AdaBoost</span></span>
<span id="cb23-94"><a href="#cb23-94" aria-hidden="true" tabindex="-1"></a><span class="co"># install.packages("adabag")</span></span>
<span id="cb23-95"><a href="#cb23-95" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(adabag)</span>
<span id="cb23-96"><a href="#cb23-96" aria-hidden="true" tabindex="-1"></a>modelo <span class="ot">&lt;-</span> <span class="fu">boosting</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> treino)</span>
<span id="cb23-97"><a href="#cb23-97" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Avalia√ß√£o</span></span>
<span id="cb23-98"><a href="#cb23-98" aria-hidden="true" tabindex="-1"></a>previsoes <span class="ot">&lt;-</span> <span class="fu">predict.boosting</span>(modelo, <span class="at">newdata =</span> teste[, <span class="sc">-</span><span class="dv">5</span>])</span>
<span id="cb23-99"><a href="#cb23-99" aria-hidden="true" tabindex="-1"></a><span class="co"># Corre√ß√£o: Garante que os n√≠veis sejam id√™nticos</span></span>
<span id="cb23-100"><a href="#cb23-100" aria-hidden="true" tabindex="-1"></a>previsoes_fator <span class="ot">&lt;-</span> <span class="fu">factor</span>(previsoes<span class="sc">$</span>class, <span class="at">levels =</span> <span class="fu">levels</span>(teste<span class="sc">$</span>Species))</span>
<span id="cb23-101"><a href="#cb23-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-102"><a href="#cb23-102" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Matriz de Confus√£o no conjunto de teste</span></span>
<span id="cb23-103"><a href="#cb23-103" aria-hidden="true" tabindex="-1"></a>confusao_df <span class="ot">&lt;-</span> <span class="fu">confusionMatrix</span>(</span>
<span id="cb23-104"><a href="#cb23-104" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> previsoes_fator,      <span class="co"># Usando a previs√£o corrigida</span></span>
<span id="cb23-105"><a href="#cb23-105" aria-hidden="true" tabindex="-1"></a>  <span class="at">reference =</span> teste<span class="sc">$</span>Species   <span class="co"># Os valores reais</span></span>
<span id="cb23-106"><a href="#cb23-106" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-107"><a href="#cb23-107" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb23-108"><a href="#cb23-108" aria-hidden="true" tabindex="-1"></a>  confusao_df<span class="sc">$</span>table,</span>
<span id="cb23-109"><a href="#cb23-109" aria-hidden="true" tabindex="-1"></a>  <span class="at">caption =</span> <span class="st">"Matriz de Confus√£o - AdaBoost"</span></span>
<span id="cb23-110"><a href="#cb23-110" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb23-111"><a href="#cb23-111" aria-hidden="true" tabindex="-1"></a>  kableExtra<span class="sc">::</span><span class="fu">kable_styling</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>)</span>
<span id="cb23-112"><a href="#cb23-112" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. C√°lculo da Acur√°cia</span></span>
<span id="cb23-113"><a href="#cb23-113" aria-hidden="true" tabindex="-1"></a>acuracia <span class="ot">&lt;-</span> <span class="fu">sum</span>(previsoes_fator <span class="sc">==</span> teste<span class="sc">$</span>Species) <span class="sc">/</span> <span class="fu">nrow</span>(teste)</span>
<span id="cb23-114"><a href="#cb23-114" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Acur√°cia do AdaBoost no conjunto iris:"</span>, <span class="fu">percent</span>(acuracia, <span class="at">accuracy =</span> <span class="fl">0.01</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb23-115"><a href="#cb23-115" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-116"><a href="#cb23-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-117"><a href="#cb23-117" aria-hidden="true" tabindex="-1"></a>Uma refer√™ncia detalhada √©: <span class="co">[</span><span class="ot">@hastie09</span><span class="co">]</span>, este livro √© considerado a b√≠blia do aprendizado de m√°quina e dedica um cap√≠tulo inteiro (Chapter 10: Boosting and Additive Trees) ao conceito de Boosting e ao AdaBoost, explicando-o de forma rigorosa e detalhada, com foco em sua base estat√≠stica e matem√°tica.</span>
<span id="cb23-118"><a href="#cb23-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-119"><a href="#cb23-119" aria-hidden="true" tabindex="-1"></a><span class="fu">## Aglomerativo Hierarchical Clustering</span></span>
<span id="cb23-120"><a href="#cb23-120" aria-hidden="true" tabindex="-1"></a>Fam√≠lia hier√°rquica de m√©todos de agrupamento que unem observa√ß√µes progressivamente. Come√ßa com cada ponto como um cluster individual e funde os mais pr√≥ximos iterativamente, formando uma √°rvore dendrograma de baixo para cima.  </span>
<span id="cb23-121"><a href="#cb23-121" aria-hidden="true" tabindex="-1"></a>Crit√©rios de liga√ß√£o (single, complete, average) definem a dist√¢ncia entre clusters.  </span>
<span id="cb23-122"><a href="#cb23-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-123"><a href="#cb23-123" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exemplo em R ‚Äì clustering aglomerativo com hclust: </span></span>
<span id="cb23-126"><a href="#cb23-126" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-127"><a href="#cb23-127" aria-hidden="true" tabindex="-1"></a>dist_matrix <span class="ot">&lt;-</span> <span class="fu">dist</span>(iris[, <span class="sc">-</span><span class="dv">5</span>]) </span>
<span id="cb23-128"><a href="#cb23-128" aria-hidden="true" tabindex="-1"></a>hc <span class="ot">&lt;-</span> <span class="fu">hclust</span>(dist_matrix, <span class="at">method =</span> <span class="st">"complete"</span>) </span>
<span id="cb23-129"><a href="#cb23-129" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(hc) <span class="co"># Dendrograma</span></span>
<span id="cb23-130"><a href="#cb23-130" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-131"><a href="#cb23-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-132"><a href="#cb23-132" aria-hidden="true" tabindex="-1"></a>Veja o metodo contr√°rio a esse , o <span class="co">[</span><span class="ot">Divisive Hierarchical Clustering</span><span class="co">](#divisive_hierarchical_clustering)</span>.</span>
<span id="cb23-133"><a href="#cb23-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-134"><a href="#cb23-134" aria-hidden="true" tabindex="-1"></a><span class="fu">## AIC ‚Äì Akaike Information Criterion (Crit√©rio de Akaike)</span></span>
<span id="cb23-135"><a href="#cb23-135" aria-hidden="true" tabindex="-1"></a>√çndice de sele√ß√£o de modelos usado amplamente em modelos estat√≠sticos e regress√µes generalizadas. Baseia-se na teoria da informa√ß√£o, penalizando a complexidade do modelo para evitar overfitting.  </span>
<span id="cb23-136"><a href="#cb23-136" aria-hidden="true" tabindex="-1"></a>Calculado como: </span>
<span id="cb23-137"><a href="#cb23-137" aria-hidden="true" tabindex="-1"></a>$$\text{AIC} = 2k - 2\ln(L)$$  </span>
<span id="cb23-138"><a href="#cb23-138" aria-hidden="true" tabindex="-1"></a>Onde: $k$ √© o n√∫mero de par√¢metros do modelo e $L$ √© a verossimilhan√ßa m√°xima do modelo.  </span>
<span id="cb23-139"><a href="#cb23-139" aria-hidden="true" tabindex="-1"></a>Modelos com menor AIC s√£o preferidos.  </span>
<span id="cb23-140"><a href="#cb23-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-141"><a href="#cb23-141" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exemplo: compara√ß√£o de modelos lineares com AIC: </span></span>
<span id="cb23-144"><a href="#cb23-144" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-145"><a href="#cb23-145" aria-hidden="true" tabindex="-1"></a><span class="co"># Repare que removi os sinais de "+" que indicam quebra de linha no console</span></span>
<span id="cb23-146"><a href="#cb23-146" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">tibble</span>( </span>
<span id="cb23-147"><a href="#cb23-147" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">5</span>, <span class="at">sd =</span> <span class="dv">2</span>),</span>
<span id="cb23-148"><a href="#cb23-148" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Aqui o tibble permite chamar o x1 criado na linha acima</span></span>
<span id="cb23-149"><a href="#cb23-149" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="dv">2</span>), </span>
<span id="cb23-150"><a href="#cb23-150" aria-hidden="true" tabindex="-1"></a>  <span class="at">x3 =</span> x2 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">3</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb23-151"><a href="#cb23-151" aria-hidden="true" tabindex="-1"></a>) <span class="sc">|&gt;</span> </span>
<span id="cb23-152"><a href="#cb23-152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb23-153"><a href="#cb23-153" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="dv">3</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>x1 <span class="sc">-</span> <span class="fl">1.5</span><span class="sc">*</span>x2 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x3 <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">2</span>)</span>
<span id="cb23-154"><a href="#cb23-154" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb23-155"><a href="#cb23-155" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(df)</span>
<span id="cb23-156"><a href="#cb23-156" aria-hidden="true" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2, <span class="at">data =</span> df) </span>
<span id="cb23-157"><a href="#cb23-157" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> df) </span>
<span id="cb23-158"><a href="#cb23-158" aria-hidden="true" tabindex="-1"></a>aic_values <span class="ot">&lt;-</span> <span class="fu">AIC</span>(model1, model2) </span>
<span id="cb23-159"><a href="#cb23-159" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(aic_values)</span>
<span id="cb23-160"><a href="#cb23-160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-161"><a href="#cb23-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-162"><a href="#cb23-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-163"><a href="#cb23-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-164"><a href="#cb23-164" aria-hidden="true" tabindex="-1"></a><span class="fu">## Artificial Neural Networks (ANNs)</span></span>
<span id="cb23-165"><a href="#cb23-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-166"><a href="#cb23-166" aria-hidden="true" tabindex="-1"></a>S√£o sistemas de computa√ß√£o inspirados na arquitetura de neur√¥nios biol√≥gicos, formalizados como composi√ß√µes de fun√ß√µes n√£o-lineares $Œ∏(ùêñùê± + ùêõ)$, onde $ùêñ$ denota matrizes de pesos sin√°pticos, $Œ∏$ √© uma fun√ß√£o de ativa√ß√£o (ReLU, sigm√≥ide, tanh) e $b$ vi√©s (bias) . A capacidade de aproximadores universais (HORNIK et al., 1989) garante que ANNs com uma camada oculta suficientemente larga podem modelar qualquer fun√ß√£o cont√≠nua em dom√≠nio compacto.\</span>
<span id="cb23-167"><a href="#cb23-167" aria-hidden="true" tabindex="-1"></a>Refer√™ncia: <span class="co">[</span><span class="ot">@hornik89</span><span class="co">]</span>.</span>
<span id="cb23-168"><a href="#cb23-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-169"><a href="#cb23-169" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exemplo em R: Rede feed-forward para regress√£o com pacote `{nnet}`</span></span>
<span id="cb23-170"><a href="#cb23-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-171"><a href="#cb23-171" aria-hidden="true" tabindex="-1"></a>A rede feed-forward √© um tipo de rede neural artificial onde as conex√µes entre os n√≥s n√£o formam ciclos. Ela √© amplamente utilizada para tarefas de regress√£o e classifica√ß√£o. No R, o pacote <span class="in">`{nnet}`</span> oferece uma maneira simples de implementar redes feed-forward.</span>
<span id="cb23-172"><a href="#cb23-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-175"><a href="#cb23-175" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-176"><a href="#cb23-176" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb23-177"><a href="#cb23-177" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Gera√ß√£o de Dados N√ÉO-LINEARES: Redes neurais brilham onde a linearidade falha. </span></span>
<span id="cb23-178"><a href="#cb23-178" aria-hidden="true" tabindex="-1"></a><span class="co"># Vamos criar uma fun√ß√£o seno com ru√≠do.</span></span>
<span id="cb23-179"><a href="#cb23-179" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb23-180"><a href="#cb23-180" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, <span class="dv">0</span>, <span class="dv">10</span>) <span class="co"># Valores entre 0 e 10</span></span>
<span id="cb23-181"><a href="#cb23-181" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">sin</span>(x) <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">sd =</span> <span class="fl">0.2</span>) <span class="co"># Seno + ru√≠do</span></span>
<span id="cb23-182"><a href="#cb23-182" aria-hidden="true" tabindex="-1"></a>dados <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb23-183"><a href="#cb23-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-184"><a href="#cb23-184" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Separa√ß√£o Treino/Teste (Boas pr√°ticas)</span></span>
<span id="cb23-185"><a href="#cb23-185" aria-hidden="true" tabindex="-1"></a>indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span>N, <span class="at">size =</span> <span class="fl">0.8</span> <span class="sc">*</span> N)</span>
<span id="cb23-186"><a href="#cb23-186" aria-hidden="true" tabindex="-1"></a>treino <span class="ot">&lt;-</span> dados[indices, ]</span>
<span id="cb23-187"><a href="#cb23-187" aria-hidden="true" tabindex="-1"></a>teste  <span class="ot">&lt;-</span> dados[<span class="sc">-</span>indices, ]</span>
<span id="cb23-188"><a href="#cb23-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-189"><a href="#cb23-189" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Ajuste do Modelo (Regress√£o)</span></span>
<span id="cb23-190"><a href="#cb23-190" aria-hidden="true" tabindex="-1"></a><span class="co"># size: neur√¥nios na camada oculta</span></span>
<span id="cb23-191"><a href="#cb23-191" aria-hidden="true" tabindex="-1"></a><span class="co"># linout = TRUE: essencial para regress√£o (sa√≠da linear, n√£o sigmoide)</span></span>
<span id="cb23-192"><a href="#cb23-192" aria-hidden="true" tabindex="-1"></a>modelo_ann <span class="ot">&lt;-</span> <span class="fu">nnet</span>(y <span class="sc">~</span> x, </span>
<span id="cb23-193"><a href="#cb23-193" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> treino, </span>
<span id="cb23-194"><a href="#cb23-194" aria-hidden="true" tabindex="-1"></a>                   <span class="at">size =</span> <span class="dv">10</span>, </span>
<span id="cb23-195"><a href="#cb23-195" aria-hidden="true" tabindex="-1"></a>                   <span class="at">linout =</span> <span class="cn">TRUE</span>, </span>
<span id="cb23-196"><a href="#cb23-196" aria-hidden="true" tabindex="-1"></a>                   <span class="at">decay =</span> <span class="fl">0.001</span>, </span>
<span id="cb23-197"><a href="#cb23-197" aria-hidden="true" tabindex="-1"></a>                   <span class="at">maxit =</span> <span class="dv">1000</span>, </span>
<span id="cb23-198"><a href="#cb23-198" aria-hidden="true" tabindex="-1"></a>                   <span class="at">trace =</span> <span class="cn">FALSE</span>) <span class="co"># trace=FALSE limpa o console</span></span>
<span id="cb23-199"><a href="#cb23-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-200"><a href="#cb23-200" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Avalia√ß√£o</span></span>
<span id="cb23-201"><a href="#cb23-201" aria-hidden="true" tabindex="-1"></a>previsoes <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo_ann, teste)</span>
<span id="cb23-202"><a href="#cb23-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-203"><a href="#cb23-203" aria-hidden="true" tabindex="-1"></a><span class="co"># C√°lculo do Erro Quadr√°tico M√©dio (MSE)</span></span>
<span id="cb23-204"><a href="#cb23-204" aria-hidden="true" tabindex="-1"></a>mse <span class="ot">&lt;-</span> <span class="fu">mean</span>((teste<span class="sc">$</span>y <span class="sc">-</span> previsoes)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb23-205"><a href="#cb23-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-206"><a href="#cb23-206" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Erro Quadr√°tico M√©dio (MSE) no teste:"</span>, <span class="fu">round</span>(mse, <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb23-207"><a href="#cb23-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-208"><a href="#cb23-208" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualiza√ß√£o </span></span>
<span id="cb23-209"><a href="#cb23-209" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Prepara√ß√£o: Adicionar as previs√µes ao data frame de teste</span></span>
<span id="cb23-210"><a href="#cb23-210" aria-hidden="true" tabindex="-1"></a>dados_plot <span class="ot">&lt;-</span> teste <span class="sc">%&gt;%</span></span>
<span id="cb23-211"><a href="#cb23-211" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">predito =</span> previsoes)</span>
<span id="cb23-212"><a href="#cb23-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-213"><a href="#cb23-213" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Visualiza√ß√£o</span></span>
<span id="cb23-214"><a href="#cb23-214" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dados_plot, <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb23-215"><a href="#cb23-215" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Camada dos dados REAIS</span></span>
<span id="cb23-216"><a href="#cb23-216" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Note que definimos color="Real" DENTRO do aes() para criar a legenda</span></span>
<span id="cb23-217"><a href="#cb23-217" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">color =</span> <span class="st">"Real"</span>, <span class="at">shape =</span> <span class="st">"Real"</span>), </span>
<span id="cb23-218"><a href="#cb23-218" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="dv">2</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb23-219"><a href="#cb23-219" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Camada dos dados PREVISTOS</span></span>
<span id="cb23-220"><a href="#cb23-220" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> predito, <span class="at">color =</span> <span class="st">"Previsto"</span>, <span class="at">shape =</span> <span class="st">"Previsto"</span>), </span>
<span id="cb23-221"><a href="#cb23-221" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="dv">3</span>, <span class="at">stroke =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb23-222"><a href="#cb23-222" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Personaliza√ß√£o manual para imitar o estilo do R Base (cinza/vermelho e c√≠rculo/x)</span></span>
<span id="cb23-223"><a href="#cb23-223" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">name =</span> <span class="st">"Legenda"</span>, </span>
<span id="cb23-224"><a href="#cb23-224" aria-hidden="true" tabindex="-1"></a>                     <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Real"</span> <span class="ot">=</span> <span class="st">"gray"</span>, <span class="st">"Previsto"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb23-225"><a href="#cb23-225" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_shape_manual</span>(<span class="at">name =</span> <span class="st">"Legenda"</span>, </span>
<span id="cb23-226"><a href="#cb23-226" aria-hidden="true" tabindex="-1"></a>                     <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Real"</span> <span class="ot">=</span> <span class="dv">19</span>, <span class="st">"Previsto"</span> <span class="ot">=</span> <span class="dv">4</span>)) <span class="sc">+</span></span>
<span id="cb23-227"><a href="#cb23-227" aria-hidden="true" tabindex="-1"></a>  <span class="co"># T√≠tulos e Tema</span></span>
<span id="cb23-228"><a href="#cb23-228" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"ANN: Ajuste a Fun√ß√£o Seno"</span>,</span>
<span id="cb23-229"><a href="#cb23-229" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Compara√ß√£o entre dados reais e aproxima√ß√£o da rede neural"</span>,</span>
<span id="cb23-230"><a href="#cb23-230" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Valor de Y"</span>,</span>
<span id="cb23-231"><a href="#cb23-231" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Valor de X"</span>) <span class="sc">+</span></span>
<span id="cb23-232"><a href="#cb23-232" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span>
<span id="cb23-233"><a href="#cb23-233" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-234"><a href="#cb23-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-235"><a href="#cb23-235" aria-hidden="true" tabindex="-1"></a><span class="fu"># B</span></span>
<span id="cb23-236"><a href="#cb23-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-237"><a href="#cb23-237" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bagging (Bootstrap Aggregating)</span></span>
<span id="cb23-238"><a href="#cb23-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-239"><a href="#cb23-239" aria-hidden="true" tabindex="-1"></a>Proposto por Breiman (1996), reduz vari√¢ncia ao treinar modelos em m√∫ltiplas amostras bootstrap e agregar predi√ß√µes por vota√ß√£o majorit√°ria (classifica√ß√£o) ou m√©dia (regress√£o). A de-correla√ß√£o entre √°rvores √© cr√≠tica para ganhos de precis√£o. Exemplo em R ‚Äì floresta aleat√≥ria com randomForest: r Copy library(randomForest) rf <span class="sc">\&lt;</span>- randomForest(Species \~ ., data = iris, ntree = 1000, importance = TRUE) print(rf\$err.rate<span class="sc">\[</span>1000, "OOB"<span class="sc">\]</span>) Refer√™ncia: Breiman, L. (1996). Bagging predictors. Machine Learning, 24(2), 123-140.</span>
<span id="cb23-240"><a href="#cb23-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-241"><a href="#cb23-241" aria-hidden="true" tabindex="-1"></a><span class="fu"># C</span></span>
<span id="cb23-242"><a href="#cb23-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-243"><a href="#cb23-243" aria-hidden="true" tabindex="-1"></a><span class="fu">## Cross-Validation (CV)</span></span>
<span id="cb23-244"><a href="#cb23-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-245"><a href="#cb23-245" aria-hidden="true" tabindex="-1"></a>Estimador de erro de generaliza√ß√£o com vi√©s‚Äìvari√¢ncia controlado. O k-fold CV particiona os dados em k subconjuntos mutuamente exclusivos; cada parti√ß√£o √© usada uma vez como teste. O nested CV √© obrigat√≥rio quando h√° sintonia de hiper-par√¢metros para evitar otimismo de desempenho (Cawley &amp; Talbot, 2010). Exemplo em R ‚Äì valida√ß√£o cruzada aninhada com caret: r Copy library(caret) tc <span class="sc">\&lt;</span>- trainControl(method = "repeatedcv", number = 10, repeats = 5, search = "grid") fit <span class="sc">\&lt;</span>- train(Class \~ ., data = Sonar, method = "svmRadial", tuneLength = 15, trControl = tc) Refer√™ncia: Cawley, G. C. &amp; Talbot, N. L. C. (2010). On over-fitting in model selection and subsequent selection bias in performance evaluation. JMLR, 11, 2079-2107.</span>
<span id="cb23-246"><a href="#cb23-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-247"><a href="#cb23-247" aria-hidden="true" tabindex="-1"></a><span class="fu"># D</span></span>
<span id="cb23-248"><a href="#cb23-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-249"><a href="#cb23-249" aria-hidden="true" tabindex="-1"></a><span class="fu">## Decision Trees (√Årvores de Decis√£o)</span></span>
<span id="cb23-250"><a href="#cb23-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-251"><a href="#cb23-251" aria-hidden="true" tabindex="-1"></a>Modelos simb√≥licos que particionam recursivamente o espa√ßo de preditores via medidas de impureza (Gini, entropia ou erro de classifica√ß√£o). A complexidade √© controlada por poda cost-complexity (cp) ou restri√ß√µes de profundidade. Exemplo em R ‚Äì √°rvore CART com rpart: r Copy library(rpart) arvore <span class="sc">\&lt;</span>- rpart(Kyphosis \~ Age + Number + Start, data = kyphosis, method = "class", cp = 0.01) rpart.plot::rpart.plot(arvore)</span>
<span id="cb23-252"><a href="#cb23-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-253"><a href="#cb23-253" aria-hidden="true" tabindex="-1"></a><span class="fu">## Divisive Hierarchical Clustering{#divisive_hierarchical_clustering}</span></span>
<span id="cb23-254"><a href="#cb23-254" aria-hidden="true" tabindex="-1"></a>Um m√©todo de agrupamento hier√°rquico divisivo emprega uma estrat√©gia de cima para baixo. Ele come√ßa colocando todos os objetos em um cluster, que √© a raiz da hierarquia. Em seguida, divide o cluster raiz em v√°rios subclusters menores e particiona recursivamente esses clusters em clusters menores. O processo de particionamento continua at√© que cada objeto esteja em seu pr√≥prio cluster ou at√© que um crit√©rio de parada seja atendido (por exemplo, n√∫mero desejado de clusters ou dist√¢ncia m√≠nima entre clusters).  </span>
<span id="cb23-255"><a href="#cb23-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-256"><a href="#cb23-256" aria-hidden="true" tabindex="-1"></a><span class="fu">### Exemplo em R ‚Äì clustering divisivo com diana</span></span>
<span id="cb23-259"><a href="#cb23-259" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb23-260"><a href="#cb23-260" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster) </span>
<span id="cb23-261"><a href="#cb23-261" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris) </span>
<span id="cb23-262"><a href="#cb23-262" aria-hidden="true" tabindex="-1"></a>div_clust <span class="ot">&lt;-</span> <span class="fu">diana</span>(iris[, <span class="sc">-</span><span class="dv">5</span>]) </span>
<span id="cb23-263"><a href="#cb23-263" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(div_clust) <span class="co"># Dendrograma</span></span>
<span id="cb23-264"><a href="#cb23-264" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb23-265"><a href="#cb23-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-266"><a href="#cb23-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-267"><a href="#cb23-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-268"><a href="#cb23-268" aria-hidden="true" tabindex="-1"></a><span class="fu"># E</span></span>
<span id="cb23-269"><a href="#cb23-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-270"><a href="#cb23-270" aria-hidden="true" tabindex="-1"></a><span class="fu">## Ensemble Learning</span></span>
<span id="cb23-271"><a href="#cb23-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-272"><a href="#cb23-272" aria-hidden="true" tabindex="-1"></a>Princ√≠pio de combinar preditores fracos para formar um preditor forte. Al√©m de bagging e boosting, stacking (Wolpert, 1992) usa um meta-modelo para ponderar especialistas de base. Diverg√™ncia entre componentes √© essencial (Kuncheva &amp; Whitaker, 2003). Exemplo em R ‚Äì stacking com SuperLearner: r Copy library(SuperLearner) SL.library <span class="sc">\&lt;</span>- c("SL.glm", "SL.ranger", "SL.xgboost") fitSL <span class="sc">\&lt;</span>- SuperLearner(Y = y, X = X, SL.library = SL.library, family = binomial())</span>
<span id="cb23-273"><a href="#cb23-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-274"><a href="#cb23-274" aria-hidden="true" tabindex="-1"></a><span class="fu"># F</span></span>
<span id="cb23-275"><a href="#cb23-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-276"><a href="#cb23-276" aria-hidden="true" tabindex="-1"></a><span class="fu">## Feature Scaling</span></span>
<span id="cb23-277"><a href="#cb23-277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-278"><a href="#cb23-278" aria-hidden="true" tabindex="-1"></a>Muitos algoritmos (SVM, redes neurais, k-NN) s√£o sens√≠veis √† magnitude das vari√°veis. A padroniza√ß√£o z-score (Œº = 0, œÉ = 1) ou normaliza√ß√£o min-max <span class="sc">\[</span>0, 1<span class="sc">\]</span> garante converg√™ncia num√©rica e interpretabilidade de penalidades regulares. Exemplo em R ‚Äì pipeline com recipes: r Copy library(recipes) receita <span class="sc">\&lt;</span>- recipe(y \~ ., data = df) %<span class="sc">\&gt;</span>% step_normalize(all_numeric_predictors()) %<span class="sc">\&gt;</span>% prep() df_scaled <span class="sc">\&lt;</span>- bake(receita, new_data = NULL)</span>
<span id="cb23-279"><a href="#cb23-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-280"><a href="#cb23-280" aria-hidden="true" tabindex="-1"></a><span class="fu"># G</span></span>
<span id="cb23-281"><a href="#cb23-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-282"><a href="#cb23-282" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient Descent (GD)</span></span>
<span id="cb23-283"><a href="#cb23-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-284"><a href="#cb23-284" aria-hidden="true" tabindex="-1"></a>Algoritmo de otimiza√ß√£o de primeira ordem que atualiza par√¢metros na dire√ß√£o oposta ao gradiente da fun√ß√£o de perda. GD estoc√°stico (SGD) reduz custo computacional por amostras mini-batch; adaptativos (Adam, RMSprop) ajustam taxas de aprendizado por momentos. Exemplo em R ‚Äì GD manual para regress√£o linear: r Copy gd <span class="sc">\&lt;</span>- function(X, y, lr = 0.01, epochs = 1000) { beta <span class="sc">\&lt;</span>- rep(0, ncol(X)) for(i in 1:epochs) { grad <span class="sc">\&lt;</span>- -2 <span class="sc">\*</span> t(X) %*% (y - X %*% beta) / nrow(X) beta <span class="sc">\&lt;</span>- beta - lr <span class="sc">\*</span> grad } beta }</span>
<span id="cb23-285"><a href="#cb23-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-286"><a href="#cb23-286" aria-hidden="true" tabindex="-1"></a><span class="fu"># H</span></span>
<span id="cb23-287"><a href="#cb23-287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-288"><a href="#cb23-288" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hyperparameter Tuning</span></span>
<span id="cb23-289"><a href="#cb23-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-290"><a href="#cb23-290" aria-hidden="true" tabindex="-1"></a>Espa√ßo de configura√ß√µes externas ao modelo (n√∫mero de vizinhos, C de SVM, profundidade de √°rvore) √© otimizado via busca em grade, aleat√≥ria (Bergstra &amp; Bengio, 2012) ou bayesiana (TPE, Gaussian Process). Exemplo em R ‚Äì bayesiano com mlr3tuning: r Copy library(mlr3tuning) task <span class="sc">\&lt;</span>- tsk("sonar") learner <span class="sc">\&lt;</span>- lrn("classif.svm", type = "C-classification", kernel = "radial") search_space <span class="sc">\&lt;</span>- ps(C = p_dbl(1e-1, 1e3), sigma = p_dbl(1e-4, 1)) tuner <span class="sc">\&lt;</span>- tnr("mbo", n_evals = 30)</span>
<span id="cb23-291"><a href="#cb23-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-292"><a href="#cb23-292" aria-hidden="true" tabindex="-1"></a><span class="fu"># I</span></span>
<span id="cb23-293"><a href="#cb23-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-294"><a href="#cb23-294" aria-hidden="true" tabindex="-1"></a><span class="fu">## Instance-Based Learning</span></span>
<span id="cb23-295"><a href="#cb23-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-296"><a href="#cb23-296" aria-hidden="true" tabindex="-1"></a>Fam√≠lia de algoritmos que adiam generaliza√ß√£o at√© o momento da predi√ß√£o, armazenando exemplos (k-NN, kernel regression). A complexidade de predi√ß√£o √© O(n), exigindo estruturas de indexa√ß√£o (KD-tree, ball-tree) ou proje√ß√µes de baixa dimensionalidade. Exemplo em R ‚Äì k-NN com FNN: r Copy library(FNN) knn_pred <span class="sc">\&lt;</span>- knn.reg(train = treino<span class="sc">\[</span>, -1<span class="sc">\]</span>, test = teste<span class="sc">\[</span>, -1<span class="sc">\]</span>, y = treino\$y, k = 5)</span>
<span id="cb23-297"><a href="#cb23-297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-298"><a href="#cb23-298" aria-hidden="true" tabindex="-1"></a><span class="fu"># J</span></span>
<span id="cb23-299"><a href="#cb23-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-300"><a href="#cb23-300" aria-hidden="true" tabindex="-1"></a><span class="fu">## Jaccard Index</span></span>
<span id="cb23-301"><a href="#cb23-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-302"><a href="#cb23-302" aria-hidden="true" tabindex="-1"></a>Medida de similaridade de conjuntos J(A,B) = <span class="sc">\|</span>A ‚à© B<span class="sc">\|</span> / <span class="sc">\|</span>A ‚à™ B<span class="sc">\|</span>. √ötil em dados bin√°rios (presen√ßa/aus√™ncia) ou comunidades em grafos. Exemplo em R: r Copy jaccard <span class="sc">\&lt;</span>- function(a, b) { length(intersect(a, b)) / length(union(a, b)) }</span>
<span id="cb23-303"><a href="#cb23-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-304"><a href="#cb23-304" aria-hidden="true" tabindex="-1"></a><span class="fu"># K</span></span>
<span id="cb23-305"><a href="#cb23-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-306"><a href="#cb23-306" aria-hidden="true" tabindex="-1"></a><span class="fu">## K-Nearest Neighbors (KNN)</span></span>
<span id="cb23-307"><a href="#cb23-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-308"><a href="#cb23-308" aria-hidden="true" tabindex="-1"></a>Classificador n√£o-param√©trico que atribui classe majorit√°ria entre os k vizinhos mais pr√≥ximos. A escolha de k via CV balancea vi√©s‚Äìvari√¢ncia; dist√¢ncias ponderadas (IDW) reduzem influ√™ncia de vizinhos distantes. Exemplo em R ‚Äì tuning de k: r Copy library(caret) fit <span class="sc">\&lt;</span>- train(Class \~ ., data = Sonar, method = "knn", tuneGrid = data.frame(k = seq(1, 25, by = 2)))</span>
<span id="cb23-309"><a href="#cb23-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-310"><a href="#cb23-310" aria-hidden="true" tabindex="-1"></a><span class="fu"># L</span></span>
<span id="cb23-311"><a href="#cb23-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-312"><a href="#cb23-312" aria-hidden="true" tabindex="-1"></a><span class="fu">## Logistic Regression</span></span>
<span id="cb23-313"><a href="#cb23-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-314"><a href="#cb23-314" aria-hidden="true" tabindex="-1"></a>Modelo linear generalizado com fun√ß√£o de liga√ß√£o logit, garantindo probabilidades em <span class="sc">\[</span>0, 1<span class="sc">\]</span>. A interpreta√ß√£o via odds-ratio √© cl√°ssica em epidemiologia. Regulariza√ß√£o L1 (lasso) permite sele√ß√£o de vari√°veis. Exemplo em R ‚Äì regress√£o log√≠stica com glmnet: r Copy library(glmnet) cvfit <span class="sc">\&lt;</span>- cv.glmnet(x = x, y = y, family = "binomial", alpha = 1) coef(cvfit, s = "lambda.min")</span>
<span id="cb23-315"><a href="#cb23-315" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-316"><a href="#cb23-316" aria-hidden="true" tabindex="-1"></a><span class="fu"># M</span></span>
<span id="cb23-317"><a href="#cb23-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-318"><a href="#cb23-318" aria-hidden="true" tabindex="-1"></a><span class="fu">## Model Overfitting</span></span>
<span id="cb23-319"><a href="#cb23-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-320"><a href="#cb23-320" aria-hidden="true" tabindex="-1"></a>Situa√ß√£o emindo a fun√ß√£o de risco emp√≠rico ‚â™ risco verdadeiro, indicando captura de ru√≠do. Diagn√≥stico via curva de valida√ß√£o (training √ó validation loss) ou complexidade VC. Solu√ß√µes: penaliza√ß√£o, early stopping, aumento de dados. Refer√™ncia: Vapnik, V. (1998). Statistical Learning Theory. Wiley.</span>
<span id="cb23-321"><a href="#cb23-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-322"><a href="#cb23-322" aria-hidden="true" tabindex="-1"></a><span class="fu"># N</span></span>
<span id="cb23-323"><a href="#cb23-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-324"><a href="#cb23-324" aria-hidden="true" tabindex="-1"></a><span class="fu">## Normalization</span></span>
<span id="cb23-325"><a href="#cb23-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-326"><a href="#cb23-326" aria-hidden="true" tabindex="-1"></a>Transforma√ß√£o que reescala vari√°veis para intervalo fixo, comum em redes neurais. A normaliza√ß√£o por lote (batch norm) acelera converg√™ncia reduzindo covari√¢ncia interna (Ioffe &amp; Szegedy, 2015). Exemplo em R ‚Äì batch norm em keras: r Copy library(keras) model %<span class="sc">\&gt;</span>% layer_batch_normalization()</span>
<span id="cb23-327"><a href="#cb23-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-328"><a href="#cb23-328" aria-hidden="true" tabindex="-1"></a><span class="fu"># O</span></span>
<span id="cb23-329"><a href="#cb23-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-330"><a href="#cb23-330" aria-hidden="true" tabindex="-1"></a><span class="fu">## Outliers</span></span>
<span id="cb23-331"><a href="#cb23-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-332"><a href="#cb23-332" aria-hidden="true" tabindex="-1"></a>Observa√ß√µes que violam pressuposto de distribui√ß√£o cont√≠nua ou homocedasticidade. Detectados via dist√¢ncia de Mahalanobis, LOF ou Isolation Forest. Em modelos lineares, leverage e Cook‚Äôs D quantificam influ√™ncia. Exemplo em R: r Copy library(isotree) iso <span class="sc">\&lt;</span>- isolation.forest(df, ntrees = 500) scores <span class="sc">\&lt;</span>- predict(iso, df)</span>
<span id="cb23-333"><a href="#cb23-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-334"><a href="#cb23-334" aria-hidden="true" tabindex="-1"></a><span class="fu"># P</span></span>
<span id="cb23-335"><a href="#cb23-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-336"><a href="#cb23-336" aria-hidden="true" tabindex="-1"></a><span class="fu">## Principal Component Analysis (PCA)</span></span>
<span id="cb23-337"><a href="#cb23-337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-338"><a href="#cb23-338" aria-hidden="true" tabindex="-1"></a>Decomposi√ß√£o ortogonal que maximiza vari√¢ncia projetada, equivalente √† decomposi√ß√£o em valores singulares (SVD) da matriz centrada. PCA √© usada para visualiza√ß√£o, ru√≠do filtrado e redu√ß√£o de dimensionalidade antes de algoritmos pesados. Exemplo em R: r Copy pca <span class="sc">\&lt;</span>- prcomp(df, center = TRUE, scale. = TRUE) biplot(pca)</span>
<span id="cb23-339"><a href="#cb23-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-340"><a href="#cb23-340" aria-hidden="true" tabindex="-1"></a><span class="fu"># Q</span></span>
<span id="cb23-341"><a href="#cb23-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-342"><a href="#cb23-342" aria-hidden="true" tabindex="-1"></a><span class="fu">## Q-Learning</span></span>
<span id="cb23-343"><a href="#cb23-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-344"><a href="#cb23-344" aria-hidden="true" tabindex="-1"></a>Algoritmo de aprendizado por refor√ßo off-policy que estima fun√ß√£o Q<span class="sc">\*</span>(s,a) via atualiza√ß√£o de Bellman. A converg√™ncia √© garantida sob visita√ß√£o infinita de pares (s,a) com taxa de aprendizado decrescente. Exemplo em R ‚Äì pacote ReinforcementLearning: r Copy library(ReinforcementLearning) data("gridworld") model <span class="sc">\&lt;</span>- ReinforcementLearning(data = gridworld, s = "state", a = "action", r = "reward", s_new = "next_state")</span>
<span id="cb23-345"><a href="#cb23-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-346"><a href="#cb23-346" aria-hidden="true" tabindex="-1"></a><span class="fu"># R</span></span>
<span id="cb23-347"><a href="#cb23-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-348"><a href="#cb23-348" aria-hidden="true" tabindex="-1"></a><span class="fu">## Regularization</span></span>
<span id="cb23-349"><a href="#cb23-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-350"><a href="#cb23-350" aria-hidden="true" tabindex="-1"></a>T√©cnica que adiciona penalidade Œ©(Œ≤) √† fun√ß√£o de perda, impondo trade-off vi√©s‚Äìvari√¢ncia. Ridge (L2) encolhe coeficientes, lasso (L1) promove esparsidade, elastic-net combina ambas. Exemplo em R ‚Äì elastic-net com glmnet: r Copy cvfit <span class="sc">\&lt;</span>- cv.glmnet(x, y, alpha = 0.5) <span class="sc">\#</span> 0.5 = elastic-net</span>
<span id="cb23-351"><a href="#cb23-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-352"><a href="#cb23-352" aria-hidden="true" tabindex="-1"></a><span class="fu"># S</span></span>
<span id="cb23-353"><a href="#cb23-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-354"><a href="#cb23-354" aria-hidden="true" tabindex="-1"></a><span class="fu">## Support Vector Machines (SVM)</span></span>
<span id="cb23-355"><a href="#cb23-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-356"><a href="#cb23-356" aria-hidden="true" tabindex="-1"></a>Classificador de margem m√°xima que resolve problema de otimiza√ß√£o quadr√°tica convexo. O kernel trick permite espa√ßos de Hilbert de alta dimens√£o sem custo computacional expl√≠cito. Exemplo em R ‚Äì SVM radial com e1071: r Copy library(e1071) fit <span class="sc">\&lt;</span>- svm(Class \~ ., data = treino, kernel = "radial", cost = 10, gamma = 0.1)</span>
<span id="cb23-357"><a href="#cb23-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-358"><a href="#cb23-358" aria-hidden="true" tabindex="-1"></a><span class="fu"># T</span></span>
<span id="cb23-359"><a href="#cb23-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-360"><a href="#cb23-360" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Set</span></span>
<span id="cb23-361"><a href="#cb23-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-362"><a href="#cb23-362" aria-hidden="true" tabindex="-1"></a>Conjunto de dados usado para estimar par√¢metros do modelo. Deve ser representativo da popula√ß√£o; t√©cnicas de amostragem estratificada preservam propor√ß√µes de classe. O tamanho ideal depende da taxa de cobertura do espa√ßo de caracter√≠sticas (Cover &amp; Hart, 1967).</span>
<span id="cb23-363"><a href="#cb23-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-364"><a href="#cb23-364" aria-hidden="true" tabindex="-1"></a><span class="fu"># U</span></span>
<span id="cb23-365"><a href="#cb23-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-366"><a href="#cb23-366" aria-hidden="true" tabindex="-1"></a><span class="fu">## Underfitting</span></span>
<span id="cb23-367"><a href="#cb23-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-368"><a href="#cb23-368" aria-hidden="true" tabindex="-1"></a>Modelo com capacidade insuficiente (alto vi√©s) n√£o captura estrutura dos dados. Indicado por erro de treino elevado. Solu√ß√µes: aumentar complexidade, adicionar features, reduzir regulariza√ß√£o.</span>
<span id="cb23-369"><a href="#cb23-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-370"><a href="#cb23-370" aria-hidden="true" tabindex="-1"></a><span class="fu"># V</span></span>
<span id="cb23-371"><a href="#cb23-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-372"><a href="#cb23-372" aria-hidden="true" tabindex="-1"></a><span class="fu">## Validation Set</span></span>
<span id="cb23-373"><a href="#cb23-373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-374"><a href="#cb23-374" aria-hidden="true" tabindex="-1"></a>Dados separados do treino para ajuste de hiper-par√¢metros, evitando vazamento de informa√ß√£o. Em datasets pequenos, cross-validation interno √© prefer√≠vel.</span>
<span id="cb23-375"><a href="#cb23-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-376"><a href="#cb23-376" aria-hidden="true" tabindex="-1"></a><span class="fu"># W</span></span>
<span id="cb23-377"><a href="#cb23-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-378"><a href="#cb23-378" aria-hidden="true" tabindex="-1"></a><span class="fu">## Weight Initialization</span></span>
<span id="cb23-379"><a href="#cb23-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-380"><a href="#cb23-380" aria-hidden="true" tabindex="-1"></a>Valores iniciais influenciam converg√™ncia e qualidade de m√≠nimo. Xavier/Glorot idealiza vari√¢ncia 2/(fan_in + fan_out) para sigm√≥ides; He inicializa com 2/fan_in para ReLU. Exemplo em R ‚Äì inicializa√ß√£o He no keras: r Copy layer_dense(units = 128, activation = "relu", kernel_initializer = "he_normal")</span>
<span id="cb23-381"><a href="#cb23-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-382"><a href="#cb23-382" aria-hidden="true" tabindex="-1"></a><span class="fu"># X</span></span>
<span id="cb23-383"><a href="#cb23-383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-384"><a href="#cb23-384" aria-hidden="true" tabindex="-1"></a><span class="fu">## XGBoost</span></span>
<span id="cb23-385"><a href="#cb23-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-386"><a href="#cb23-386" aria-hidden="true" tabindex="-1"></a>Implementa√ß√£o escalon√°vel de gradient boosting comÁ®ÄÁñèÊï∞ÊçÆ (sparsity-aware), regulariza√ß√£o L1/L2 em √°rvores, e paraleliza√ß√£o porÁâπÂæÅÂàÜÂùó. Domina competi√ß√µes tabulares. Exemplo em R: r Copy library(xgboost) dtrain <span class="sc">\&lt;</span>- xgb.DMatrix(data = as.matrix(treino<span class="sc">\[</span>, -1<span class="sc">\]</span>), label = treino\$label) param <span class="sc">\&lt;</span>- list(max_depth = 6, eta = 0.05, subsample = 0.8, colsample_bytree = 0.8, objective = "binary:logistic") bst <span class="sc">\&lt;</span>- xgb.train(param, dtrain, nrounds = 400, watchlist = list(train = dtrain), early_stopping_rounds = 10)</span>
<span id="cb23-387"><a href="#cb23-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-388"><a href="#cb23-388" aria-hidden="true" tabindex="-1"></a><span class="fu"># Y</span></span>
<span id="cb23-389"><a href="#cb23-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-390"><a href="#cb23-390" aria-hidden="true" tabindex="-1"></a><span class="fu">## Y-Axis</span></span>
<span id="cb23-391"><a href="#cb23-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-392"><a href="#cb23-392" aria-hidden="true" tabindex="-1"></a>Nos gr√°ficos de curvas de aprendizado, representa m√©trica de desempenho (acur√°cia, AUC, RMSE) ou erro emp√≠rico. A an√°lise de gap entre treino e valida√ß√£o revela overfitting/underfitting.</span>
<span id="cb23-393"><a href="#cb23-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-394"><a href="#cb23-394" aria-hidden="true" tabindex="-1"></a><span class="fu"># Z</span></span>
<span id="cb23-395"><a href="#cb23-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-396"><a href="#cb23-396" aria-hidden="true" tabindex="-1"></a><span class="fu">## Z-Score</span></span>
<span id="cb23-397"><a href="#cb23-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-398"><a href="#cb23-398" aria-hidden="true" tabindex="-1"></a>Escore padronizado z = (x ‚àí Œº)/œÉ, indicando desvios em unidades de desvio-padr√£o. Utilizado para detec√ß√£o de outliers (<span class="sc">\|</span>z<span class="sc">\|</span> <span class="sc">\&gt;</span> 3) e normaliza√ß√£o de features. Exemplo em R: r Copy z <span class="sc">\&lt;</span>- scale(df\$x)</span>
<span id="cb23-399"><a href="#cb23-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-400"><a href="#cb23-400" aria-hidden="true" tabindex="-1"></a>Refer√™ncias gerais</span>
<span id="cb23-401"><a href="#cb23-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-402"><a href="#cb23-402" aria-hidden="true" tabindex="-1"></a>Bergstra, J. &amp; Bengio, Y. (2012). Random search for hyper-parameter optimization. JMLR, 13, 281-305.</span>
<span id="cb23-403"><a href="#cb23-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-404"><a href="#cb23-404" aria-hidden="true" tabindex="-1"></a>Breiman, L. (2001). Random forests. Machine Learning, 45(1), 5-32.</span>
<span id="cb23-405"><a href="#cb23-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-406"><a href="#cb23-406" aria-hidden="true" tabindex="-1"></a>Cover, T. &amp; Hart, P. (1967). Nearest neighbor pattern classification. IEEE TIT, 13(1), 21-27.</span>
<span id="cb23-407"><a href="#cb23-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-408"><a href="#cb23-408" aria-hidden="true" tabindex="-1"></a>Ioffe, S. &amp; Szegedy, C. (2015). Batch normalization: Accelerating deep network training by reducing internal covariate shift. ICML.</span>
</code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->




<script src="Machine_Learning_A_a_Z_files/libs/quarto-html/zenscroll-min.js"></script>
</body></html>